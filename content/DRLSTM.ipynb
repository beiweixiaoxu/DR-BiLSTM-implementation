{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRLSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6kToRQ2ka5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import os\n",
        "import zipfile\n",
        "import pickle\n",
        "import fnmatch\n",
        "import json\n",
        "import string\n",
        "\n",
        "from collections import Counter\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from drlstm.utils import correct_predictions\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from drlstm.data import NLIDataset\n",
        "from drlstm.model import DRLSTM\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6Ef0flLjFfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.840B.300d.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Liy_wnJrc_lI",
        "colab_type": "code",
        "outputId": "2a69ab99-1b00-4b47-a9e7-39a96a9a6189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-27 22:53:49--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 94550081 (90M) [application/zip]\n",
            "Saving to: ‘snli_1.0.zip’\n",
            "\n",
            "snli_1.0.zip        100%[===================>]  90.17M  18.1MB/s    in 7.9s    \n",
            "\n",
            "2019-11-27 22:53:58 (11.5 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bdjhjo3dJEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip snli_1.0.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKV3Ykh-koFg",
        "colab_type": "code",
        "outputId": "66c0a4fe-97a8-415c-935a-9733281e2fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mount Google Drive (to save the downloaded files)\n",
        "#from google.colab import drive\n",
        "#drive.mount('/gdrive')\n",
        "\n",
        "# Copy word vectors *to* Google Drive\n",
        "# You only need to do this once.\n",
        "# Please comment this out after running it. \n",
        "#!cp \"glove.840B.300d.zip\" \"/gdrive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhMVtHQBlTFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If you copied the word vectors to your Drive before,\n",
        "# here is where you copy them back to the Colab notebook.\n",
        "\n",
        "# Copy Glove vectors *from* Google Drive\n",
        "#!cp \"/gdrive/My Drive/glove.840B.300d.zip\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEeItdRTn4V9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOgl6MGFtiMi",
        "colab_type": "code",
        "outputId": "67a823ca-0ce4-4d19-f4f3-6a7fbae0066c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('glove.840B.300d.txt', encoding='utf-8')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 2196016 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEGUQIJAndl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Preprocessor and dataset definition for NLI.\n",
        "\"\"\"\n",
        "# Aurelien Coet, 2018.\n",
        "\n",
        "class Preprocessor(object):\n",
        "    \"\"\"\n",
        "    Preprocessor class for Natural Language Inference datasets.\n",
        "\n",
        "    The class can be used to read NLI datasets, build worddicts for them\n",
        "    and transform their premises, hypotheses and labels into lists of\n",
        "    integer indices.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 lowercase=False,\n",
        "                 ignore_punctuation=False,\n",
        "                 num_words=None,\n",
        "                 stopwords=[],\n",
        "                 labeldict={},\n",
        "                 bos=None,\n",
        "                 eos=None):\n",
        "\n",
        "        self.lowercase = lowercase\n",
        "        self.ignore_punctuation = ignore_punctuation\n",
        "        self.num_words = num_words\n",
        "        self.stopwords = stopwords\n",
        "        self.labeldict = labeldict\n",
        "        self.bos = bos\n",
        "        self.eos = eos\n",
        "\n",
        "    def read_data(self, filepath):\n",
        "        \"\"\"\n",
        "        Read the premises, hypotheses and labels from some NLI dataset's\n",
        "        file and return them in a dictionary. The file should be in the same\n",
        "        form as SNLI's .txt files.\n",
        "\n",
        "        Args:\n",
        "            filepath: The path to a file containing some premises, hypotheses\n",
        "                and labels that must be read. The file should be formatted in\n",
        "                the same way as the SNLI (and MultiNLI) dataset.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing three lists, one for the premises, one for\n",
        "            the hypotheses, and one for the labels in the input data.\n",
        "        \"\"\"\n",
        "        with open(filepath, \"r\", encoding=\"utf8\") as input_data:\n",
        "            ids, premises, hypotheses, labels = [], [], [], []\n",
        "\n",
        "            # Translation tables to remove parentheses and punctuation from\n",
        "            # strings.\n",
        "            parentheses_table = str.maketrans({\"(\": None, \")\": None})\n",
        "            punct_table = str.maketrans({key: \" \"\n",
        "                                         for key in string.punctuation})\n",
        "\n",
        "            # Ignore the headers on the first line of the file.\n",
        "            next(input_data)\n",
        "\n",
        "            for line in input_data:\n",
        "                line = line.strip().split(\"\\t\")\n",
        "\n",
        "                # Ignore sentences that have no gold label.\n",
        "                if line[0] == \"-\":\n",
        "                    continue\n",
        "\n",
        "                pair_id = line[7]\n",
        "                premise = line[1]\n",
        "                hypothesis = line[2]\n",
        "\n",
        "                # Remove '(' and ')' from the premises and hypotheses.\n",
        "                premise = premise.translate(parentheses_table)\n",
        "                hypothesis = hypothesis.translate(parentheses_table)\n",
        "\n",
        "                if self.lowercase:\n",
        "                    premise = premise.lower()\n",
        "                    hypothesis = hypothesis.lower()\n",
        "\n",
        "                if self.ignore_punctuation:\n",
        "                    premise = premise.translate(punct_table)\n",
        "                    hypothesis = hypothesis.translate(punct_table)\n",
        "\n",
        "                # Each premise and hypothesis is split into a list of words.\n",
        "                premises.append([w for w in premise.rstrip().split()\n",
        "                                 if w not in self.stopwords])\n",
        "                hypotheses.append([w for w in hypothesis.rstrip().split()\n",
        "                                   if w not in self.stopwords])\n",
        "                labels.append(line[0])\n",
        "                ids.append(pair_id)\n",
        "\n",
        "            return {\"ids\": ids,\n",
        "                    \"premises\": premises,\n",
        "                    \"hypotheses\": hypotheses,\n",
        "                    \"labels\": labels}\n",
        "\n",
        "    def build_worddict(self, data):\n",
        "        \"\"\"\n",
        "        Build a dictionary associating words to unique integer indices for\n",
        "        some dataset. The worddict can then be used to transform the words\n",
        "        in datasets to their indices.\n",
        "\n",
        "        Args:\n",
        "            data: A dictionary containing the premises, hypotheses and\n",
        "                labels of some NLI dataset, in the format returned by the\n",
        "                'read_data' method of the Preprocessor class.\n",
        "        \"\"\"\n",
        "        words = []\n",
        "        [words.extend(sentence) for sentence in data[\"premises\"]]\n",
        "        [words.extend(sentence) for sentence in data[\"hypotheses\"]]\n",
        "\n",
        "        counts = Counter(words)\n",
        "        num_words = self.num_words\n",
        "        if self.num_words is None:\n",
        "            num_words = len(counts)\n",
        "\n",
        "        self.worddict = {}\n",
        "\n",
        "        # Special indices are used for padding, out-of-vocabulary words, and\n",
        "        # beginning and end of sentence tokens.\n",
        "        self.worddict[\"_PAD_\"] = 0\n",
        "        self.worddict[\"_OOV_\"] = 1\n",
        "\n",
        "        offset = 2\n",
        "        if self.bos:\n",
        "            self.worddict[\"_BOS_\"] = 2\n",
        "            offset += 1\n",
        "        if self.eos:\n",
        "            self.worddict[\"_EOS_\"] = 3\n",
        "            offset += 1\n",
        "\n",
        "        for i, word in enumerate(counts.most_common(num_words)):\n",
        "            self.worddict[word[0]] = i + offset\n",
        "\n",
        "        if self.labeldict == {}:\n",
        "            label_names = set(data[\"labels\"])\n",
        "            self.labeldict = {label_name: i\n",
        "                              for i, label_name in enumerate(label_names)}\n",
        "\n",
        "    def words_to_indices(self, sentence):\n",
        "        \"\"\"\n",
        "        Transform the words in a sentence to their corresponding integer\n",
        "        indices.\n",
        "\n",
        "        Args:\n",
        "            sentence: A list of words that must be transformed to indices.\n",
        "\n",
        "        Returns:\n",
        "            A list of indices.\n",
        "        \"\"\"\n",
        "        indices = []\n",
        "        # Include the beggining of sentence token at the start of the sentence\n",
        "        # if one is defined.\n",
        "        if self.bos:\n",
        "            indices.append(self.worddict[\"_BOS_\"])\n",
        "\n",
        "        for word in sentence:\n",
        "            if word in self.worddict:\n",
        "                index = self.worddict[word]\n",
        "            else:\n",
        "                # Words absent from 'worddict' are treated as a special\n",
        "                # out-of-vocabulary word (OOV).\n",
        "                index = self.worddict[\"_OOV_\"]\n",
        "            indices.append(index)\n",
        "        # Add the end of sentence token at the end of the sentence if one\n",
        "        # is defined.\n",
        "        if self.eos:\n",
        "            indices.append(self.worddict[\"_EOS_\"])\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def indices_to_words(self, indices):\n",
        "        \"\"\"\n",
        "        Transform the indices in a list to their corresponding words in\n",
        "        the object's worddict.\n",
        "\n",
        "        Args:\n",
        "            indices: A list of integer indices corresponding to words in\n",
        "                the Preprocessor's worddict.\n",
        "\n",
        "        Returns:\n",
        "            A list of words.\n",
        "        \"\"\"\n",
        "        return [list(self.worddict.keys())[list(self.worddict.values())\n",
        "                                           .index(i)]\n",
        "                for i in indices]\n",
        "\n",
        "    def transform_to_indices(self, data):\n",
        "        \"\"\"\n",
        "        Transform the words in the premises and hypotheses of a dataset, as\n",
        "        well as their associated labels, to integer indices.\n",
        "\n",
        "        Args:\n",
        "            data: A dictionary containing lists of premises, hypotheses\n",
        "                and labels, in the format returned by the 'read_data'\n",
        "                method of the Preprocessor class.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary containing the transformed premises, hypotheses and\n",
        "            labels.\n",
        "        \"\"\"\n",
        "        transformed_data = {\"ids\": [],\n",
        "                            \"premises\": [],\n",
        "                            \"hypotheses\": [],\n",
        "                            \"labels\": []}\n",
        "\n",
        "        for i, premise in enumerate(data[\"premises\"]):\n",
        "            # Ignore sentences that have a label for which no index was\n",
        "            # defined in 'labeldict'.\n",
        "            label = data[\"labels\"][i]\n",
        "            if label not in self.labeldict and label != \"hidden\":\n",
        "                continue\n",
        "\n",
        "            transformed_data[\"ids\"].append(data[\"ids\"][i])\n",
        "\n",
        "            if label == \"hidden\":\n",
        "                transformed_data[\"labels\"].append(-1)\n",
        "            else:\n",
        "                transformed_data[\"labels\"].append(self.labeldict[label])\n",
        "\n",
        "            indices = self.words_to_indices(premise)\n",
        "            transformed_data[\"premises\"].append(indices)\n",
        "\n",
        "            indices = self.words_to_indices(data[\"hypotheses\"][i])\n",
        "            transformed_data[\"hypotheses\"].append(indices)\n",
        "\n",
        "        return transformed_data\n",
        "\n",
        "    def build_embedding_matrix(self, embeddings_file):\n",
        "        \"\"\"\n",
        "        Build an embedding matrix with pretrained weights for object's\n",
        "        worddict.\n",
        "\n",
        "        Args:\n",
        "            embeddings_file: A file containing pretrained word embeddings.\n",
        "\n",
        "        Returns:\n",
        "            A numpy matrix of size (num_words+n_special_tokens, embedding_dim)\n",
        "            containing pretrained word embeddings (the +n_special_tokens is for\n",
        "            the padding and out-of-vocabulary tokens, as well as BOS and EOS if\n",
        "            they're used).\n",
        "        \"\"\"\n",
        "        # Load the word embeddings in a dictionnary.\n",
        "        embeddings = {}\n",
        "        with open(embeddings_file, \"r\", encoding=\"utf8\") as input_data:\n",
        "            for line in input_data:\n",
        "                line = line.split()\n",
        "\n",
        "                try:\n",
        "                    # Check that the second element on the line is the start\n",
        "                    # of the embedding and not another word. Necessary to\n",
        "                    # ignore multiple word lines.\n",
        "                    float(line[1])\n",
        "                    word = line[0]\n",
        "                    if word in self.worddict:\n",
        "                        embeddings[word] = line[1:]\n",
        "\n",
        "                # Ignore lines corresponding to multiple words separated\n",
        "                # by spaces.\n",
        "                except ValueError:\n",
        "                    continue\n",
        "\n",
        "        num_words = len(self.worddict)\n",
        "        embedding_dim = len(list(embeddings.values())[0])\n",
        "        embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "        # Actual building of the embedding matrix.\n",
        "        missed = 0\n",
        "        for word, i in self.worddict.items():\n",
        "            if word in embeddings:\n",
        "                embedding_matrix[i] = np.array(embeddings[word], dtype=float)\n",
        "            else:\n",
        "                if word == \"_PAD_\":\n",
        "                    continue\n",
        "                missed += 1\n",
        "                # Out of vocabulary words are initialised with random gaussian\n",
        "                # samples.\n",
        "                embedding_matrix[i] = np.random.normal(size=(embedding_dim))\n",
        "        print(\"Missed words: \", missed)\n",
        "\n",
        "        return embedding_matrix\n",
        "\n",
        "\n",
        "class NLIDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for Natural Language Inference datasets.\n",
        "\n",
        "    The class can be used to read preprocessed datasets where the premises,\n",
        "    hypotheses and labels have been transformed to unique integer indices\n",
        "    (this can be done with the 'preprocess_data' script in the 'scripts'\n",
        "    folder of this repository).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 padding_idx=0,\n",
        "                 max_premise_length=None,\n",
        "                 max_hypothesis_length=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: A dictionary containing the preprocessed premises,\n",
        "                hypotheses and labels of some dataset.\n",
        "            padding_idx: An integer indicating the index being used for the\n",
        "                padding token in the preprocessed data. Defaults to 0.\n",
        "            max_premise_length: An integer indicating the maximum length\n",
        "                accepted for the sequences in the premises. If set to None,\n",
        "                the length of the longest premise in 'data' is used.\n",
        "                Defaults to None.\n",
        "            max_hypothesis_length: An integer indicating the maximum length\n",
        "                accepted for the sequences in the hypotheses. If set to None,\n",
        "                the length of the longest hypothesis in 'data' is used.\n",
        "                Defaults to None.\n",
        "        \"\"\"\n",
        "        self.premises_lengths = [len(seq) for seq in data[\"premises\"]]\n",
        "        self.max_premise_length = max_premise_length\n",
        "        if self.max_premise_length is None:\n",
        "            self.max_premise_length = max(self.premises_lengths)\n",
        "\n",
        "        self.hypotheses_lengths = [len(seq) for seq in data[\"hypotheses\"]]\n",
        "        self.max_hypothesis_length = max_hypothesis_length\n",
        "        if self.max_hypothesis_length is None:\n",
        "            self.max_hypothesis_length = max(self.hypotheses_lengths)\n",
        "\n",
        "        self.num_sequences = len(data[\"premises\"])\n",
        "\n",
        "        self.data = {\"ids\": [],\n",
        "                     \"premises\": torch.ones((self.num_sequences,\n",
        "                                             self.max_premise_length),\n",
        "                                            dtype=torch.long) * padding_idx,\n",
        "                     \"hypotheses\": torch.ones((self.num_sequences,\n",
        "                                               self.max_hypothesis_length),\n",
        "                                              dtype=torch.long) * padding_idx,\n",
        "                     \"labels\": torch.tensor(data[\"labels\"], dtype=torch.long)}\n",
        "\n",
        "        for i, premise in enumerate(data[\"premises\"]):\n",
        "            self.data[\"ids\"].append(data[\"ids\"][i])\n",
        "            end = min(len(premise), self.max_premise_length)\n",
        "            self.data[\"premises\"][i][:end] = torch.tensor(premise[:end])\n",
        "\n",
        "            hypothesis = data[\"hypotheses\"][i]\n",
        "            end = min(len(hypothesis), self.max_hypothesis_length)\n",
        "            self.data[\"hypotheses\"][i][:end] = torch.tensor(hypothesis[:end])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_sequences\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\"id\": self.data[\"ids\"][index],\n",
        "                \"premise\": self.data[\"premises\"][index],\n",
        "                \"premise_length\": min(self.premises_lengths[index],\n",
        "                                      self.max_premise_length),\n",
        "                \"hypothesis\": self.data[\"hypotheses\"][index],\n",
        "                \"hypothesis_length\": min(self.hypotheses_lengths[index],\n",
        "                                         self.max_hypothesis_length),\n",
        "                \"label\": self.data[\"labels\"][index]}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsdzdx5gkTHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetch_data.py\n",
        "\"\"\"\n",
        "Fetch datasets and pretrained word embeddings for the model.\n",
        "\n",
        "By default, the script downloads the following.\n",
        "    - The SNLI corpus;\n",
        "    - GloVe word embeddings (840B - 300d).\n",
        "\"\"\"\n",
        "# Aurelien Coet, 2018.\n",
        "\n",
        "def download(url, targetdir):\n",
        "    \"\"\"\n",
        "    Download a file and save it in some target directory.\n",
        "\n",
        "    Args:\n",
        "        url: The url from which the file must be downloaded.\n",
        "        targetdir: The path to the directory where the file must be saved.\n",
        "\n",
        "    Returns:\n",
        "        The path to the downloaded file.\n",
        "    \"\"\"\n",
        "    print(\"* Downloading data from {}...\".format(url))\n",
        "    filepath = os.path.join(targetdir, url.split('/')[-1])\n",
        "    !wget.download(url, filepath)\n",
        "    return filepath\n",
        "\n",
        "\n",
        "def unzip(filepath):\n",
        "    \"\"\"\n",
        "    Extract the data from a zipped file and delete the archive.\n",
        "\n",
        "    Args:\n",
        "        filepath: The path to the zipped file.\n",
        "    \"\"\"\n",
        "    print(\"\\n* Extracting: {}...\".format(filepath))\n",
        "    dirpath = os.path.dirname(filepath)\n",
        "    with zipfile.ZipFile(filepath) as zf:\n",
        "        for name in zf.namelist():\n",
        "            # Ignore useless files in archives.\n",
        "            if \"__MACOSX\" in name or\\\n",
        "               \".DS_Store\" in name or\\\n",
        "               \"Icon\" in name:\n",
        "                continue\n",
        "            zf.extract(name, dirpath)\n",
        "    # Delete the archive once the data has been extracted.\n",
        "    os.remove(filepath)\n",
        "\n",
        "\n",
        "def download_unzip(url, targetdir):\n",
        "    \"\"\"\n",
        "    Download and unzip data from some url and save it in a target directory.\n",
        "\n",
        "    Args:\n",
        "        url: The url to download the data from.\n",
        "        targetdir: The target directory in which to download and unzip the\n",
        "                   data.\n",
        "    \"\"\"\n",
        "    filepath = os.path.join(targetdir, url.split('/')[-1])\n",
        "    target = os.path.join(targetdir,\n",
        "                          \".\".join((url.split('/')[-1]).split('.')[:-1]))\n",
        "\n",
        "    if not os.path.exists(targetdir):\n",
        "        print(\"* Creating target directory {}...\".format(targetdir))\n",
        "        os.makedirs(targetdir)\n",
        "\n",
        "    # Skip download and unzipping if the unzipped data is already available.\n",
        "    if os.path.exists(target) or os.path.exists(target + \".txt\"):\n",
        "        print(\"* Found unzipped data in {}, skipping download and unzip...\"\n",
        "              .format(targetdir))\n",
        "    # Skip downloading if the zipped data is already available.\n",
        "    elif os.path.exists(filepath):\n",
        "        print(\"* Found zipped data in {} - skipping download...\"\n",
        "              .format(targetdir))\n",
        "        unzip(filepath)\n",
        "    # Download and unzip otherwise.\n",
        "    else:\n",
        "        unzip(download(url, targetdir))\n",
        "\n",
        "# Default data.\n",
        "snli_url = \"https://nlp.stanford.edu/projects/snli/snli_1.0.zip\"\n",
        "glove_url = \"http://www-nlp.stanford.edu/data/glove.840B.300d.zip\"\n",
        "\n",
        "\n",
        "dataset_url = snli_url\n",
        "embeddings_url = glove_url\n",
        "target_dir = os.path.join(\".\", \"data\")\n",
        "\n",
        "if not os.path.exists(target_dir):\n",
        "    os.makedirs(target_dir)\n",
        "\n",
        "print(20*\"=\", \"Fetching the dataset:\", 20*'=')\n",
        "download_unzip(dataset_url, os.path.join(target_dir, \"dataset\"))\n",
        "\n",
        "print(20*\"=\", \"Fetching the word embeddings:\", 20*\"=\")\n",
        "download_unzip(embeddings_url,\n",
        "                os.path.join(target_dir, \"embeddings\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKUq2uPUnGrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Preprocess the SNLI dataset and word embeddings to be used by the model.\n",
        "\"\"\"\n",
        "# Aurelien Coet, 2018.\n",
        "\n",
        "def preprocess_SNLI_data(inputdir,\n",
        "                         embeddings_file,\n",
        "                         targetdir,\n",
        "                         lowercase=False,\n",
        "                         ignore_punctuation=False,\n",
        "                         num_words=None,\n",
        "                         stopwords=[],\n",
        "                         labeldict={},\n",
        "                         bos=None,\n",
        "                         eos=None):\n",
        "\n",
        "    if not os.path.exists(targetdir):\n",
        "        os.makedirs(targetdir)\n",
        "\n",
        "    # Retrieve the train, dev and test data files from the dataset directory.\n",
        "    train_file = \"\"\n",
        "    dev_file = \"\"\n",
        "    test_file = \"\"\n",
        "    for file in os.listdir(inputdir):\n",
        "        if fnmatch.fnmatch(file, \"*_train.txt\"):\n",
        "            train_file = file\n",
        "        elif fnmatch.fnmatch(file, \"*_dev.txt\"):\n",
        "            dev_file = file\n",
        "        elif fnmatch.fnmatch(file, \"*_test.txt\"):\n",
        "            test_file = file\n",
        "\n",
        "    # -------------------- Train data preprocessing -------------------- #\n",
        "    preprocessor = Preprocessor(lowercase=lowercase,\n",
        "                                ignore_punctuation=ignore_punctuation,\n",
        "                                num_words=num_words,\n",
        "                                stopwords=stopwords,\n",
        "                                labeldict=labeldict,\n",
        "                                bos=bos,\n",
        "                                eos=eos)\n",
        "\n",
        "    print(20*\"=\", \" Preprocessing train set \", 20*\"=\")\n",
        "    print(\"\\t* Reading data...\")\n",
        "    data = preprocessor.read_data(os.path.join(inputdir, train_file))\n",
        "\n",
        "    print(\"\\t* Computing worddict and saving it...\")\n",
        "    preprocessor.build_worddict(data)\n",
        "    with open(os.path.join(targetdir, \"worddict.pkl\"), \"wb\") as pkl_file:\n",
        "        pickle.dump(preprocessor.worddict, pkl_file)\n",
        "\n",
        "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
        "    transformed_data = preprocessor.transform_to_indices(data)\n",
        "    print(\"\\t* Saving result...\")\n",
        "    with open(os.path.join(targetdir, \"train_data.pkl\"), \"wb\") as pkl_file:\n",
        "        pickle.dump(transformed_data, pkl_file)\n",
        "\n",
        "    # -------------------- Validation data preprocessing -------------------- #\n",
        "    print(20*\"=\", \" Preprocessing dev set \", 20*\"=\")\n",
        "    print(\"\\t* Reading data...\")\n",
        "    data = preprocessor.read_data(os.path.join(inputdir, dev_file))\n",
        "\n",
        "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
        "    transformed_data = preprocessor.transform_to_indices(data)\n",
        "    print(\"\\t* Saving result...\")\n",
        "    with open(os.path.join(targetdir, \"dev_data.pkl\"), \"wb\") as pkl_file:\n",
        "        pickle.dump(transformed_data, pkl_file)\n",
        "\n",
        "    # -------------------- Test data preprocessing -------------------- #\n",
        "    print(20*\"=\", \" Preprocessing test set \", 20*\"=\")\n",
        "    print(\"\\t* Reading data...\")\n",
        "    data = preprocessor.read_data(os.path.join(inputdir, test_file))\n",
        "\n",
        "    print(\"\\t* Transforming words in premises and hypotheses to indices...\")\n",
        "    transformed_data = preprocessor.transform_to_indices(data)\n",
        "    print(\"\\t* Saving result...\")\n",
        "    with open(os.path.join(targetdir, \"test_data.pkl\"), \"wb\") as pkl_file:\n",
        "        pickle.dump(transformed_data, pkl_file)\n",
        "\n",
        "    # -------------------- Embeddings preprocessing -------------------- #\n",
        "    print(20*\"=\", \" Preprocessing embeddings \", 20*\"=\")\n",
        "    print(\"\\t* Building embedding matrix and saving it...\")\n",
        "    embed_matrix = preprocessor.build_embedding_matrix(embeddings_file)\n",
        "    with open(os.path.join(targetdir, \"embeddings.pkl\"), \"wb\") as pkl_file:\n",
        "        pickle.dump(embed_matrix, pkl_file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvq537lfn9oC",
        "colab_type": "code",
        "outputId": "eb569982-55ef-4da1-92c3-6e9dfeaeff48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "default_config = \"/content/config/preprocessing/snli_preprocessing.json\"\n",
        "\n",
        "config = default_config\n",
        "script_dir = \"/\"\n",
        "\n",
        "if config == default_config:\n",
        "    config_path = os.path.join(script_dir, config)\n",
        "else:\n",
        "    config_path = config\n",
        "\n",
        "with open(os.path.normpath(config_path), \"r\") as cfg_file:\n",
        "    config = json.load(cfg_file)\n",
        "\n",
        "preprocess_SNLI_data(\n",
        "    os.path.normpath(os.path.join(script_dir, config[\"data_dir\"])),\n",
        "    os.path.normpath(os.path.join(script_dir, config[\"embeddings_file\"])),\n",
        "    os.path.normpath(os.path.join(script_dir, config[\"target_dir\"])),\n",
        "    lowercase=config[\"lowercase\"],\n",
        "    ignore_punctuation=config[\"ignore_punctuation\"],\n",
        "    num_words=config[\"num_words\"],\n",
        "    stopwords=config[\"stopwords\"],\n",
        "    labeldict=config[\"labeldict\"],\n",
        "    bos=config[\"bos\"],\n",
        "    eos=config[\"eos\"]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================  Preprocessing train set  ====================\n",
            "\t* Reading data...\n",
            "\t* Computing worddict and saving it...\n",
            "\t* Transforming words in premises and hypotheses to indices...\n",
            "\t* Saving result...\n",
            "====================  Preprocessing dev set  ====================\n",
            "\t* Reading data...\n",
            "\t* Transforming words in premises and hypotheses to indices...\n",
            "\t* Saving result...\n",
            "====================  Preprocessing test set  ====================\n",
            "\t* Reading data...\n",
            "\t* Transforming words in premises and hypotheses to indices...\n",
            "\t* Saving result...\n",
            "====================  Preprocessing embeddings  ====================\n",
            "\t* Building embedding matrix and saving it...\n",
            "Missed words:  4045\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBKoLx0wrB-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions for training and validating models.\n",
        "\"\"\"\n",
        "def train(model,\n",
        "          dataloader,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          epoch_number,\n",
        "          max_gradient_norm):\n",
        "\n",
        "    # Switch the model to train mode.\n",
        "    model.train()\n",
        "    device = model.device\n",
        "\n",
        "    epoch_start = time.time()\n",
        "    batch_time_avg = 0.0\n",
        "    running_loss = 0.0\n",
        "    correct_preds = 0\n",
        "\n",
        "    tqdm_batch_iterator = tqdm(dataloader)\n",
        "    for batch_index, batch in enumerate(tqdm_batch_iterator):\n",
        "        batch_start = time.time()\n",
        "\n",
        "        # Move input and output data to the GPU if it is used.\n",
        "        premises = batch[\"premise\"].to(device)\n",
        "        premises_lengths = batch[\"premise_length\"].to(device)\n",
        "        hypotheses = batch[\"hypothesis\"].to(device)\n",
        "        hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits, probs = model(premises,\n",
        "                              premises_lengths,\n",
        "                              hypotheses,\n",
        "                              hypotheses_lengths)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_gradient_norm)\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time_avg += time.time() - batch_start\n",
        "        running_loss += loss.item()\n",
        "        correct_preds += correct_predictions(probs, labels)\n",
        "\n",
        "        description = \"Avg. batch proc. time: {:.4f}s, loss: {:.4f}\"\\\n",
        "                      .format(batch_time_avg/(batch_index+1),\n",
        "                              running_loss/(batch_index+1))\n",
        "        tqdm_batch_iterator.set_description(description)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = correct_preds / len(dataloader.dataset)\n",
        "\n",
        "    return epoch_time, epoch_loss, epoch_accuracy\n",
        "\n",
        "\n",
        "def validate(model, dataloader, criterion):\n",
        "    # Switch to evaluate mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "\n",
        "    epoch_start = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            premises = batch[\"premise\"].to(device)\n",
        "            premises_lengths = batch[\"premise_length\"].to(device)\n",
        "            hypotheses = batch[\"hypothesis\"].to(device)\n",
        "            hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            logits, probs = model(premises,\n",
        "                                  premises_lengths,\n",
        "                                  hypotheses,\n",
        "                                  hypotheses_lengths)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            running_accuracy += correct_predictions(probs, labels)\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_accuracy = running_accuracy / (len(dataloader.dataset))\n",
        "\n",
        "    return epoch_time, epoch_loss, epoch_accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1D3EsxOsGyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Train the model on the preprocessed SNLI dataset.\n",
        "\"\"\"\n",
        "# Aurelien Coet, 2018.\n",
        "\n",
        "from drlstm.data import NLIDataset\n",
        "\n",
        "def main(train_file,\n",
        "         valid_file,\n",
        "         embeddings_file,\n",
        "         target_dir,\n",
        "         hidden_size=300,\n",
        "         dropout=0.5,\n",
        "         num_classes=3,\n",
        "         epochs=1,\n",
        "         batch_size=32,\n",
        "         lr=0.0004,\n",
        "         patience=5,\n",
        "         max_grad_norm=10.0,\n",
        "         checkpoint=None):\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(20 * \"=\", \" Preparing for training \", 20 * \"=\")\n",
        "\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "\n",
        "    # -------------------- Data loading ------------------- #\n",
        "    print(\"\\t* Loading training data...\")\n",
        "    with open(train_file, \"rb\") as pkl:\n",
        "        train_data = NLIDataset(pickle.load(pkl))\n",
        "\n",
        "    train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "    print(\"\\t* Loading validation data...\")\n",
        "    with open(valid_file, \"rb\") as pkl:\n",
        "        valid_data = NLIDataset(pickle.load(pkl))\n",
        "\n",
        "    valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    # -------------------- Model definition ------------------- #\n",
        "    print(\"\\t* Building model...\")\n",
        "    with open(embeddings_file, \"rb\") as pkl:\n",
        "        embeddings = torch.tensor(pickle.load(pkl), dtype=torch.float)\\\n",
        "                     .to(device)\n",
        "\n",
        "    model = DRLSTM(embeddings.shape[0],\n",
        "                 embeddings.shape[1],\n",
        "                 hidden_size,\n",
        "                 embeddings=embeddings,\n",
        "                 dropout=dropout,\n",
        "                 num_classes=num_classes,\n",
        "                 device=device).to(device)\n",
        "\n",
        "    # -------------------- Preparation for training  ------------------- #\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                           mode=\"max\",\n",
        "                                                           factor=0.5,\n",
        "                                                           patience=0)\n",
        "\n",
        "    best_score = 0.0\n",
        "    start_epoch = 1\n",
        "\n",
        "    # Data for loss curves plot.\n",
        "    epochs_count = []\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "\n",
        "    # Continuing training from a checkpoint if one was given as argument.\n",
        "    if checkpoint:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        best_score = checkpoint[\"best_score\"]\n",
        "\n",
        "        print(\"\\t* Training will continue on existing model from epoch {}...\"\n",
        "              .format(start_epoch))\n",
        "\n",
        "        model.load_state_dict(checkpoint[\"model\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "        epochs_count = checkpoint[\"epochs_count\"]\n",
        "        train_losses = checkpoint[\"train_losses\"]\n",
        "        valid_losses = checkpoint[\"valid_losses\"]\n",
        "\n",
        "    # Compute loss and accuracy before starting (or resuming) training.\n",
        "    _, valid_loss, valid_accuracy = validate(model,\n",
        "                                             valid_loader,\n",
        "                                             criterion)\n",
        "    print(\"\\t* Validation loss before training: {:.4f}, accuracy: {:.4f}%\"\n",
        "          .format(valid_loss, (valid_accuracy*100)))\n",
        "\n",
        "    # -------------------- Training epochs ------------------- #\n",
        "    print(\"\\n\",\n",
        "          20 * \"=\",\n",
        "          \"Training model on device: {}\".format(device),\n",
        "          20 * \"=\")\n",
        "\n",
        "    patience_counter = 0\n",
        "    for epoch in range(start_epoch, epochs+1):\n",
        "        epochs_count.append(epoch)\n",
        "\n",
        "        print(\"* Training epoch {}:\".format(epoch))\n",
        "        epoch_time, epoch_loss, epoch_accuracy = train(model,\n",
        "                                                       train_loader,\n",
        "                                                       optimizer,\n",
        "                                                       criterion,\n",
        "                                                       epoch,\n",
        "                                                       max_grad_norm)\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        print(\"-> Training time: {:.4f}s, loss = {:.4f}, accuracy: {:.4f}%\"\n",
        "              .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
        "\n",
        "        print(\"* Validation for epoch {}:\".format(epoch))\n",
        "        epoch_time, epoch_loss, epoch_accuracy = validate(model,\n",
        "                                                          valid_loader,\n",
        "                                                          criterion)\n",
        "\n",
        "        valid_losses.append(epoch_loss)\n",
        "        print(\"-> Valid. time: {:.4f}s, loss: {:.4f}, accuracy: {:.4f}%\\n\"\n",
        "              .format(epoch_time, epoch_loss, (epoch_accuracy*100)))\n",
        "\n",
        "        # Update the optimizer's learning rate with the scheduler.\n",
        "        scheduler.step(epoch_accuracy)\n",
        "\n",
        "        # Early stopping on validation accuracy.\n",
        "        if epoch_accuracy < best_score:\n",
        "            patience_counter += 1\n",
        "        else:\n",
        "            best_score = epoch_accuracy\n",
        "            patience_counter = 0\n",
        "            # Save the best model. The optimizer is not saved to avoid having\n",
        "            # a checkpoint file that is too heavy to be shared. To resume\n",
        "            # training from the best model, use the 'drlstm_*.pth.tar'\n",
        "            # checkpoints instead.\n",
        "            torch.save({\"epoch\": epoch,\n",
        "                        \"model\": model.state_dict(),\n",
        "                        \"best_score\": best_score,\n",
        "                        \"epochs_count\": epochs_count,\n",
        "                        \"train_losses\": train_losses,\n",
        "                        \"valid_losses\": valid_losses},\n",
        "                       os.path.join(target_dir, \"best.pth.tar\"))\n",
        "\n",
        "        # Save the model at each epoch.\n",
        "        print ('Saving model to')\n",
        "        print (os.path.join(target_dir, \"drlstm_{}.pth.tar\".format(epoch)))\n",
        "        torch.save({\"epoch\": epoch,\n",
        "                    \"model\": model.state_dict(),\n",
        "                    \"best_score\": best_score,\n",
        "                    \"optimizer\": optimizer.state_dict(),\n",
        "                    \"epochs_count\": epochs_count,\n",
        "                    \"train_losses\": train_losses,\n",
        "                    \"valid_losses\": valid_losses},\n",
        "                   os.path.join(target_dir, \"drlstm_{}.pth.tar\".format(epoch)))\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"-> Early stopping: patience limit reached, stopping...\")\n",
        "            break\n",
        "\n",
        "    # Plotting of the loss curves for the train and validation sets.\n",
        "    plt.figure()\n",
        "    plt.plot(epochs_count, train_losses, \"-r\")\n",
        "    plt.plot(epochs_count, valid_losses, \"-b\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend([\"Training loss\", \"Validation loss\"])\n",
        "    plt.title(\"Cross entropy loss\")\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuXvqoFB2glr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Definition of the model.\n",
        "\"\"\"\n",
        "# Aurelien Coet, 2018.\n",
        "\n",
        "from drlstm.layers import RNNDropout, Seq2SeqEncoder, SoftmaxAttention\n",
        "from drlstm.utils import get_mask, replace_masked\n",
        "\n",
        "class DRLSTM(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 embedding_dim,\n",
        "                 hidden_size,\n",
        "                 embeddings=None,\n",
        "                 padding_idx=0,\n",
        "                 dropout=0.5,\n",
        "                 num_classes=3,\n",
        "                 device=\"cpu\"):\n",
        "\n",
        "        super(DRLSTM, self).__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_classes = num_classes\n",
        "        self.dropout = dropout\n",
        "        self.device = device\n",
        "\n",
        "        self.debug = False\n",
        "\n",
        "        self._word_embedding = nn.Embedding(self.vocab_size,\n",
        "                                            self.embedding_dim,\n",
        "                                            padding_idx=padding_idx,\n",
        "                                            _weight=embeddings)\n",
        "        #print ('embedding_dim: ')\n",
        "        #print (embedding_dim)\n",
        "        if self.dropout:\n",
        "            self._rnn_dropout = RNNDropout(p=self.dropout)\n",
        "            # self._rnn_dropout = nn.Dropout(p=self.dropout)\n",
        "\n",
        "        self._encoding = Seq2SeqEncoder(nn.LSTM,\n",
        "                                        self.embedding_dim,\n",
        "                                        self.hidden_size,\n",
        "                                        bidirectional=True)\n",
        "        \n",
        "        self._encoding1 = Seq2SeqEncoder(nn.LSTM,\n",
        "                                        self.embedding_dim,\n",
        "                                        int(self.hidden_size/2),\n",
        "                                        bidirectional=True)\n",
        "        self._encoding2 = Seq2SeqEncoder(nn.LSTM,\n",
        "                                        self.hidden_size,\n",
        "                                        self.hidden_size,\n",
        "                                        bidirectional=True)\n",
        "\n",
        "        self._attention = SoftmaxAttention()\n",
        "\n",
        "        self._projection = nn.Sequential(nn.Linear(4*2*self.hidden_size,\n",
        "                                                   self.hidden_size),\n",
        "                                         nn.ReLU())\n",
        "\n",
        "        self._composition = Seq2SeqEncoder(nn.LSTM,\n",
        "                                           self.hidden_size,\n",
        "                                           self.hidden_size,\n",
        "                                           bidirectional=True)\n",
        "        \n",
        "        self._composition1 = Seq2SeqEncoder(nn.LSTM,\n",
        "                                           self.hidden_size,\n",
        "                                           self.hidden_size,\n",
        "                                           bidirectional=True)\n",
        "        \n",
        "        self._composition2 = Seq2SeqEncoder(nn.LSTM,\n",
        "                                           2*self.hidden_size,\n",
        "                                           self.hidden_size,\n",
        "                                           bidirectional=True)\n",
        "\n",
        "        self._classification = nn.Sequential(nn.Dropout(p=self.dropout),\n",
        "                                             nn.Linear(2*4*self.hidden_size,\n",
        "                                                       self.hidden_size),\n",
        "                                             nn.Tanh(),\n",
        "                                             nn.Dropout(p=self.dropout),\n",
        "                                             nn.Linear(self.hidden_size,\n",
        "                                                       self.num_classes))\n",
        "\n",
        "        # Initialize all weights and biases in the model.\n",
        "        self.apply(_init_model_weights)\n",
        "\n",
        "    def forward(self,\n",
        "                premises,\n",
        "                premises_lengths,\n",
        "                hypotheses,\n",
        "                hypotheses_lengths):\n",
        "\n",
        "        premises_mask = get_mask(premises, premises_lengths).to(self.device)\n",
        "        hypotheses_mask = get_mask(hypotheses, hypotheses_lengths)\\\n",
        "            .to(self.device)\n",
        "\n",
        "        embedded_premises = self._word_embedding(premises)\n",
        "        embedded_hypotheses = self._word_embedding(hypotheses)\n",
        "\n",
        "        if self.debug:\n",
        "          print (embedded_premises.size()) # 32,61,300\n",
        "          print (embedded_hypotheses.size()) # 32,57,300\n",
        "        #if self.dropout:\n",
        "        #    embedded_premises = self._rnn_dropout(embedded_premises)\n",
        "        #    embedded_hypotheses = self._rnn_dropout(embedded_hypotheses)\n",
        "\n",
        "\n",
        "        \n",
        "        encoded_premises = self._encoding(embedded_premises,\n",
        "                                          premises_lengths)\n",
        "        encoded_hypotheses = self._encoding(embedded_hypotheses,\n",
        "                                            hypotheses_lengths)\n",
        "        \n",
        "        \n",
        "        encoded_premises1 = self._encoding1(embedded_premises,\n",
        "                                          premises_lengths)\n",
        "        encoded_hypotheses1 = self._encoding1(embedded_hypotheses,\n",
        "                                            hypotheses_lengths)\n",
        "        \n",
        "        if self.debug:\n",
        "          print ('encoded_premises1')\n",
        "          print (encoded_premises1.size())\n",
        "          print ('encoded_hypo1')\n",
        "          print (encoded_hypotheses1.size())\n",
        "\n",
        "        encoded_premises2 = self._encoding2(encoded_hypotheses1,\n",
        "                                          hypotheses_lengths)\n",
        "        encoded_hypotheses2 = self._encoding2(encoded_premises1,\n",
        "                                            premises_lengths)\n",
        "        \n",
        "        if self.debug:\n",
        "          print ('encoded_premises2')\n",
        "          print (encoded_premises2.size())\n",
        "          print ('encoded_hypo2')\n",
        "          print (encoded_hypotheses2.size())\n",
        "        \n",
        "        \"\"\"\n",
        "        encoded_premises1\n",
        "        torch.Size([32, 36, 300])\n",
        "        encoded_hypo1\n",
        "        torch.Size([32, 22, 300])\n",
        "        encoded_premises2\n",
        "        torch.Size([32, 22, 600])\n",
        "        encoded_hypo2\n",
        "        torch.Size([32, 36, 600])\n",
        "        #print (premises_lengths.size()) # 32\n",
        "        #print (hypotheses_lengths.size()) # 32\n",
        "        \n",
        "        #print (encoded_premises.size()) # 32,36,600\n",
        "        #print (encoded_hypotheses.size()) # 32,22,600\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        attended_premises, attended_hypotheses =\\\n",
        "            self._attention(encoded_premises2, hypotheses_mask,\n",
        "                            encoded_hypotheses2, premises_mask)\n",
        "        \n",
        "        if self.debug:\n",
        "          print ('after attention')\n",
        "          print ('attended_premises: ')\n",
        "          print (attended_premises.size())\n",
        "          print ('attended_hypotheses: ')\n",
        "          print (attended_hypotheses.size())\n",
        "\n",
        "        enhanced_premises = torch.cat([encoded_premises2,\n",
        "                                       attended_premises,\n",
        "                                       encoded_premises2 - attended_premises,\n",
        "                                       encoded_premises2 * attended_premises],\n",
        "                                      dim=-1)\n",
        "        enhanced_hypotheses = torch.cat([encoded_hypotheses2,\n",
        "                                         attended_hypotheses,\n",
        "                                         encoded_hypotheses2 -\n",
        "                                         attended_hypotheses,\n",
        "                                         encoded_hypotheses2 *\n",
        "                                         attended_hypotheses],\n",
        "                                        dim=-1)\n",
        "       \n",
        "        if self.debug:\n",
        "          print ('enhanced_premises: ')\n",
        "          print (enhanced_premises.size())\n",
        "          print ('enhanced_hypotheses: ')\n",
        "          print (enhanced_hypotheses.size())\n",
        "        \n",
        "        projected_premises = self._projection(enhanced_premises)\n",
        "        projected_hypotheses = self._projection(enhanced_hypotheses)\n",
        "        \n",
        "        if self.debug:\n",
        "          print ('projected_premises:')\n",
        "          print (projected_premises.size())\n",
        "          print ('projected_hypotheses:')\n",
        "          print (projected_hypotheses.size())\n",
        "\n",
        "        if self.dropout:\n",
        "            projected_premises = self._rnn_dropout(projected_premises)\n",
        "            projected_hypotheses = self._rnn_dropout(projected_hypotheses)\n",
        "\n",
        "        if self.debug:\n",
        "          print ('projected_premises after dropout:')\n",
        "          print (projected_premises.size())\n",
        "          print ('projected_hypotheses after dropout:')\n",
        "          print (projected_hypotheses.size())\n",
        "        \"\"\"\n",
        "        v_ai = self._composition(projected_premises, premises_lengths)\n",
        "        v_bj = self._composition(projected_hypotheses, hypotheses_lengths)\n",
        "        print ('v_ai:')\n",
        "        print (v_ai.size())\n",
        "        print ('v_bj')\n",
        "        print (v_bj.size())\n",
        "        \"\"\"\n",
        "\n",
        "        v_ai1 = self._composition1(projected_premises, hypotheses_lengths)\n",
        "        v_bj1 = self._composition1(projected_hypotheses, premises_lengths)\n",
        "\n",
        "        if self.debug:\n",
        "          print ('v_ai1')\n",
        "          print (v_ai1.size())\n",
        "          print ('v_bj1')\n",
        "          print (v_bj1.size())\n",
        "\n",
        "        v_ai2 = self._composition2(v_ai1, hypotheses_lengths)\n",
        "        v_bj2 = self._composition2(v_bj1, premises_lengths)\n",
        "\n",
        "        if self.debug:\n",
        "          print ('v_ai2')\n",
        "          print (v_ai2.size())\n",
        "          print ('v_bj2')\n",
        "          print (v_bj2.size())\n",
        "\n",
        "        \n",
        "        # max pooling\n",
        "        v_ai = torch.max(v_ai1, v_ai2)\n",
        "        v_bj = torch.max(v_bj1, v_bj2)\n",
        "\n",
        "        if self.debug:\n",
        "          print ('v_ai after max')\n",
        "          print (v_ai.size())\n",
        "          print ('v_bj after max')\n",
        "          print (v_bj.size())\n",
        "\n",
        "        v_a_avg = torch.sum(v_bj * premises_mask.unsqueeze(1)\n",
        "                                                .transpose(2, 1), dim=1)\\\n",
        "            / torch.sum(premises_mask, dim=1, keepdim=True)\n",
        "        v_b_avg = torch.sum(v_ai * hypotheses_mask.unsqueeze(1)\n",
        "                                                  .transpose(2, 1), dim=1)\\\n",
        "            / torch.sum(hypotheses_mask, dim=1, keepdim=True)\n",
        "\n",
        "        v_a_max, _ = replace_masked(v_bj, premises_mask, -1e7).max(dim=1)\n",
        "        v_b_max, _ = replace_masked(v_ai, hypotheses_mask, -1e7).max(dim=1)\n",
        "\n",
        "        v = torch.cat([v_a_avg, v_a_max, v_b_avg, v_b_max], dim=1)\n",
        "        if self.debug:\n",
        "          print ('v:')\n",
        "          print (v.size())\n",
        "        logits = self._classification(v)\n",
        "        if self.debug:\n",
        "          print ('logits:')\n",
        "          print (logits.size())\n",
        "        probabilities = nn.functional.softmax(logits, dim=-1)\n",
        "\n",
        "        return logits, probabilities\n",
        "\n",
        "\n",
        "def _init_model_weights(module):\n",
        "    \"\"\"\n",
        "    Initialise the weights of the model.\n",
        "    \"\"\"\n",
        "    if isinstance(module, nn.Linear):\n",
        "        nn.init.xavier_uniform_(module.weight.data)\n",
        "        nn.init.constant_(module.bias.data, 0.0)\n",
        "\n",
        "    elif isinstance(module, nn.LSTM):\n",
        "        nn.init.xavier_uniform_(module.weight_ih_l0.data)\n",
        "        nn.init.orthogonal_(module.weight_hh_l0.data)\n",
        "        nn.init.constant_(module.bias_ih_l0.data, 0.0)\n",
        "        nn.init.constant_(module.bias_hh_l0.data, 0.0)\n",
        "        hidden_size = module.bias_hh_l0.data.shape[0] // 4\n",
        "        module.bias_hh_l0.data[hidden_size:(2*hidden_size)] = 1.0\n",
        "\n",
        "        if (module.bidirectional):\n",
        "            nn.init.xavier_uniform_(module.weight_ih_l0_reverse.data)\n",
        "            nn.init.orthogonal_(module.weight_hh_l0_reverse.data)\n",
        "            nn.init.constant_(module.bias_ih_l0_reverse.data, 0.0)\n",
        "            nn.init.constant_(module.bias_hh_l0_reverse.data, 0.0)\n",
        "            module.bias_hh_l0_reverse.data[hidden_size:(2*hidden_size)] = 1.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15b0_KrLs8au",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4de4083-aabe-4cf3-b957-25b07384d632"
      },
      "source": [
        "default_config = \"content/snli_training.json\"\n",
        "\n",
        "script_dir = '/'\n",
        "config = default_config\n",
        "checkpoint = None\n",
        "\n",
        "if config == default_config:\n",
        "    config_path = os.path.join(script_dir, config)\n",
        "else:\n",
        "    config_path = config\n",
        "\n",
        "with open(os.path.normpath(config_path), 'r') as config_file:\n",
        "    config = json.load(config_file)\n",
        "\n",
        "main(os.path.normpath(os.path.join(script_dir, config[\"train_data\"])),\n",
        "      os.path.normpath(os.path.join(script_dir, config[\"valid_data\"])),\n",
        "      os.path.normpath(os.path.join(script_dir, config[\"embeddings\"])),\n",
        "      os.path.normpath(os.path.join(script_dir, config[\"target_dir\"])),\n",
        "      config[\"hidden_size\"],\n",
        "      config[\"dropout\"],\n",
        "      config[\"num_classes\"],\n",
        "      config[\"epochs\"],\n",
        "      config[\"batch_size\"],\n",
        "      config[\"lr\"],\n",
        "      config[\"patience\"],\n",
        "      config[\"max_gradient_norm\"],\n",
        "      checkpoint)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================  Preparing for training  ====================\n",
            "\t* Loading training data...\n",
            "\t* Loading validation data...\n",
            "\t* Building model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drlstm/utils.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n",
            "Avg. batch proc. time: 0.0866s, loss: 1.0938:   0%|          | 1/17168 [00:00<39:03,  7.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t* Validation loss before training: 1.1002, accuracy: 32.7271%\n",
            "\n",
            " ==================== Training model on device: cuda:0 ====================\n",
            "* Training epoch 1:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0868s, loss: 0.5590: 100%|██████████| 17168/17168 [26:10<00:00, 11.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Training time: 1570.5779s, loss = 0.5590, accuracy: 77.3716%\n",
            "* Validation for epoch 1:\n",
            "-> Valid. time: 8.7780s, loss: 0.4000, accuracy: 84.7795%\n",
            "\n",
            "Saving model to\n",
            "/content/drlstm_1.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0933s, loss: 0.3670:   0%|          | 1/17168 [00:00<48:51,  5.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "* Training epoch 2:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0868s, loss: 0.3995: 100%|██████████| 17168/17168 [26:10<00:00, 10.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Training time: 1570.3708s, loss = 0.3995, accuracy: 84.9609%\n",
            "* Validation for epoch 2:\n",
            "-> Valid. time: 8.7469s, loss: 0.3770, accuracy: 85.6533%\n",
            "\n",
            "Saving model to\n",
            "/content/drlstm_2.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0932s, loss: 0.3667:   0%|          | 1/17168 [00:00<50:43,  5.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "* Training epoch 3:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0865s, loss: 0.3431: 100%|██████████| 17168/17168 [26:05<00:00, 11.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Training time: 1565.0280s, loss = 0.3431, accuracy: 87.3711%\n",
            "* Validation for epoch 3:\n",
            "-> Valid. time: 8.8455s, loss: 0.3456, accuracy: 87.0352%\n",
            "\n",
            "Saving model to\n",
            "/content/drlstm_3.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/17168 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "* Training epoch 4:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0864s, loss: 0.2993: 100%|██████████| 17168/17168 [25:59<00:00, 10.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Training time: 1559.4942s, loss = 0.2993, accuracy: 89.2485%\n",
            "* Validation for epoch 4:\n",
            "-> Valid. time: 8.8706s, loss: 0.3520, accuracy: 87.5025%\n",
            "\n",
            "Saving model to\n",
            "/content/drlstm_4.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0974s, loss: 0.3518:   0%|          | 1/17168 [00:00<44:02,  6.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "* Training epoch 5:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Avg. batch proc. time: 0.0864s, loss: 0.2617: 100%|██████████| 17168/17168 [25:59<00:00, 11.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Training time: 1559.8180s, loss = 0.2617, accuracy: 90.8158%\n",
            "* Validation for epoch 5:\n",
            "-> Valid. time: 8.7507s, loss: 0.3737, accuracy: 87.1774%\n",
            "\n",
            "Saving model to\n",
            "/content/drlstm_5.pth.tar\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkQlatRzYYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Test the model on some preprocessed dataset.\n",
        "\"\"\"\n",
        "# Aurelien Coet, 2018.\n",
        "\n",
        "def test(model, dataloader):\n",
        "    \"\"\"\n",
        "    Test the accuracy of a model on some labelled test dataset.\n",
        "\n",
        "    Args:\n",
        "        model: The torch module on which testing must be performed.\n",
        "        dataloader: A DataLoader object to iterate over some dataset.\n",
        "\n",
        "    Returns:\n",
        "        batch_time: The average time to predict the classes of a batch.\n",
        "        total_time: The total time to process the whole dataset.\n",
        "        accuracy: The accuracy of the model on the input data.\n",
        "    \"\"\"\n",
        "    # Switch the model to eval mode.\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "\n",
        "    time_start = time.time()\n",
        "    batch_time = 0.0\n",
        "    accuracy = 0.0\n",
        "\n",
        "    # Deactivate autograd for evaluation.\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch_start = time.time()\n",
        "\n",
        "            # Move input and output data to the GPU if one is used.\n",
        "            premises = batch[\"premise\"].to(device)\n",
        "            premises_lengths = batch[\"premise_length\"].to(device)\n",
        "            hypotheses = batch[\"hypothesis\"].to(device)\n",
        "            hypotheses_lengths = batch[\"hypothesis_length\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "\n",
        "            _, probs = model(premises,\n",
        "                             premises_lengths,\n",
        "                             hypotheses,\n",
        "                             hypotheses_lengths)\n",
        "\n",
        "            accuracy += correct_predictions(probs, labels)\n",
        "            batch_time += time.time() - batch_start\n",
        "\n",
        "    batch_time /= len(dataloader)\n",
        "    total_time = time.time() - time_start\n",
        "    accuracy /= (len(dataloader.dataset))\n",
        "\n",
        "    return batch_time, total_time, accuracy\n",
        "\n",
        "\n",
        "def main_test(test_file, pretrained_file, batch_size=32):\n",
        "    \"\"\"\n",
        "    Test the model with pretrained weights on some dataset.\n",
        "\n",
        "    Args:\n",
        "        test_file: The path to a file containing preprocessed NLI data.\n",
        "        pretrained_file: The path to a checkpoint produced by the\n",
        "            'train_model' script.\n",
        "        vocab_size: The number of words in the vocabulary of the model\n",
        "            being tested.\n",
        "        embedding_dim: The size of the embeddings in the model.\n",
        "        hidden_size: The size of the hidden layers in the model. Must match\n",
        "            the size used during training. Defaults to 300.\n",
        "        num_classes: The number of classes in the output of the model. Must\n",
        "            match the value used during training. Defaults to 3.\n",
        "        batch_size: The size of the batches used for testing. Defaults to 32.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(20 * \"=\", \" Preparing for testing \", 20 * \"=\")\n",
        "\n",
        "    checkpoint = torch.load(pretrained_file)\n",
        "\n",
        "    # Retrieving model parameters from checkpoint.\n",
        "    vocab_size = checkpoint[\"model\"][\"_word_embedding.weight\"].size(0)\n",
        "    embedding_dim = checkpoint[\"model\"]['_word_embedding.weight'].size(1)\n",
        "    hidden_size = checkpoint[\"model\"][\"_projection.0.weight\"].size(0)\n",
        "    num_classes = checkpoint[\"model\"][\"_classification.4.weight\"].size(0)\n",
        "\n",
        "    print(\"\\t* Loading test data...\")\n",
        "    with open(test_file, \"rb\") as pkl:\n",
        "        test_data = NLIDataset(pickle.load(pkl))\n",
        "\n",
        "    test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    print(\"\\t* Building model...\")\n",
        "    model = DRLSTM(vocab_size,\n",
        "                 embedding_dim,\n",
        "                 hidden_size,\n",
        "                 num_classes=num_classes,\n",
        "                 device=device).to(device)\n",
        "\n",
        "    model.load_state_dict(checkpoint[\"model\"])\n",
        "\n",
        "    print(20 * \"=\",\n",
        "          \" Testing model on device: {} \".format(device),\n",
        "          20 * \"=\")\n",
        "    batch_time, total_time, accuracy = test(model, test_loader)\n",
        "\n",
        "    print(\"-> Average batch processing time: {:.4f}s, total test time:\\\n",
        " {:.4f}s, accuracy: {:.4f}%\".format(batch_time, total_time, (accuracy*100)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR68D9oc0c-G",
        "colab_type": "code",
        "outputId": "8148418e-ed0f-4613-fa98-23522aaa06a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "test_data = '/content/test_data.pkl'\n",
        "checkpoint = '/content/best.pth.tar'\n",
        "batch_size = 32\n",
        "main_test(test_data,\n",
        "      checkpoint,\n",
        "      batch_size)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================  Preparing for testing  ====================\n",
            "\t* Loading test data...\n",
            "\t* Building model...\n",
            "====================  Testing model on device: cuda:0  ====================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drlstm/utils.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
            "  sequences_lengths.new_tensor(torch.arange(0, len(sequences_lengths)))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> Average batch processing time: 0.0283s, total test time: 8.7906s, accuracy: 86.5533%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}