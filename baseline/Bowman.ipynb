{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bowman.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhBAy7RsMdDc",
        "colab_type": "text"
      },
      "source": [
        "# Bowman's Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut10idNFMQ71",
        "colab_type": "text"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dKfdbsQDgJh",
        "colab_type": "code",
        "outputId": "67a8e874-3e72-4c4c-dab0-3fd30c978e82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext.data import Dataset\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "from nltk import word_tokenize\n",
        "import time\n",
        "import dill\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUcE6lFVMsnW",
        "colab_type": "text"
      },
      "source": [
        "## Make directories\n",
        "Make directories for saving data and model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU4j19JiV2kZ",
        "colab_type": "code",
        "outputId": "4eb5e3da-8b81-4ca8-cf2f-537c24686f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "\n",
        "# claim directories for saving data and model\n",
        "new_dir = ['./data', './model', './data/snli_split']\n",
        "\n",
        "# if directories not exist, make new directory\n",
        "for dir in new_dir:\n",
        "    if not os.path.exists(dir):\n",
        "        print('mkdir:', dir)\n",
        "        os.mkdir(dir)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: ./data\n",
            "mkdir: ./model\n",
            "mkdir: ./data/snli_split\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY_HL4ngM839",
        "colab_type": "text"
      },
      "source": [
        "## SNLI corpus data preprocessing\n",
        "The class to preprocess SNLI corpus.\n",
        "\n",
        "For the first time on initial, the initial function will download and split SNLI corpus to train, dev and test sets, build vocab for the corpus by using Glove 840B 300d and store them to local files. And it will also generate batch iterator for the sets. This process may take more than 5 minutes on first time.\n",
        "\n",
        "After the first time, initial function will check existence of local files, if exists, it will load directly from local file and thus can save a lot of time (within 1 minute)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T62lOGEWGhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNLIDataset(Dataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return data.interleave_keys(len(ex.premise), len(ex.hypothesis))\n",
        "\n",
        "# preprocess SNLI corpus to save time and give train, dev, test sets\n",
        "class SNLI(object):\n",
        "    def __init__(self, batch_size=4, gpu=torch.device('cuda')):\n",
        "        # set file name for train dev test sets\n",
        "        self.snli_split_path_lst = ['./data/snli_split/train', './data/snli_split/dev', './data/snli_split/test']\n",
        "\n",
        "        # set data field for text and label\n",
        "        self.TEXT = data.Field(batch_first=True, include_lengths=True, tokenize=word_tokenize, lower=True)\n",
        "        self.LABEL = data.Field(sequential=False, unk_token=None)\n",
        "\n",
        "        # split corpus\n",
        "        if self.if_splited():\n",
        "            # if already splited, load local sets\n",
        "            fields = {'premise': self.TEXT, 'hypothesis': self.TEXT, 'label': self.LABEL}\n",
        "            self.train, self.dev, self.test = self.load_split_datasets(fields)\n",
        "        else:\n",
        "            # split corpus to train, dev, test sets and save them to local\n",
        "            self.train, self.dev, self.test = datasets.SNLI.splits(self.TEXT, self.LABEL, root='data')\n",
        "            self.save_splited_sets(self.train, self.dev, self.test)\n",
        "\n",
        "\n",
        "        # build vocab for corpus\n",
        "        if os.path.exists('./data/snli_split/text_vocab') and os.path.exists('./data/snli_split/label_vocab'):\n",
        "            # if local vocab exists, load local vocab into model\n",
        "            with open('./data/snli_split/text_vocab', 'rb')as f:\n",
        "                self.TEXT.vocab = dill.load(f)\n",
        "            with open('./data/snli_split/label_vocab', 'rb')as f:\n",
        "                self.LABEL.vocab = dill.load(f)\n",
        "        else:\n",
        "            # build vocab for corpus and save it to local\n",
        "            self.TEXT.build_vocab(self.train, self.dev, self.test, vectors=GloVe(name='840B', dim=300))\n",
        "            self.LABEL.build_vocab(self.train)\n",
        "            with open('./data/snli_split/text_vocab', 'wb')as f:\n",
        "                dill.dump(self.TEXT.vocab, f)\n",
        "            with open('./data/snli_split/label_vocab', 'wb')as f:\n",
        "                dill.dump(self.LABEL.vocab, f)\n",
        "\n",
        "\n",
        "        # generate batch iterator\n",
        "        self.train_iter, self.dev_iter, self.test_iter =  data.BucketIterator.splits((self.train, self.dev, self.test), batch_size=batch_size, device=gpu)\n",
        "\n",
        "    # check local train, dev, test sets\n",
        "    def if_splited(self):\n",
        "        for path in self.snli_split_path_lst:\n",
        "            if not os.path.exists(path):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    # load dataset from local\n",
        "    def load_split_datasets(self, fields):\n",
        "        # load from local\n",
        "        with open('./data/snli_split/train', 'rb')as f:\n",
        "            train_examples = dill.load(f)\n",
        "        with open('./data/snli_split/dev', 'rb')as f:\n",
        "            dev_examples = dill.load(f)\n",
        "        with open('./data/snli_split/test', 'rb')as f:\n",
        "            test_examples = dill.load(f)\n",
        "\n",
        "        # recover\n",
        "        train = SNLIDataset(examples=train_examples, fields=fields)\n",
        "        dev = SNLIDataset(examples=dev_examples, fields=fields)\n",
        "        test = SNLIDataset(examples=test_examples, fields=fields)\n",
        "        return train, dev, test\n",
        "\n",
        "    # save datasets to local\n",
        "    def save_splited_sets(self, train, dev, test):\n",
        "        # save to local\n",
        "        with open('./data/snli_split/train', 'wb')as f:\n",
        "            dill.dump(train.examples, f)\n",
        "        with open('./data/snli_split/dev', 'wb')as f:\n",
        "            dill.dump(dev.examples, f)\n",
        "        with open('./data/snli_split/test', 'wb')as f:\n",
        "            dill.dump(test.examples, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGkJYKinOdrH",
        "colab_type": "text"
      },
      "source": [
        "## Initialize SNLI class and do preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4zrNONWwSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')\n",
        "snli = SNLI(batch_size=32, gpu=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166rJ755O7jY",
        "colab_type": "text"
      },
      "source": [
        "## Bowman's Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UHTtZ3-b1QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bowman(nn.Module):\n",
        "    def __init__(self, vocab, premise_emb=300, hypothesis_emb=300, premise_d=100, hypothesis_d=100, lstm_layers=1, dropout=0.1):\n",
        "        super(Bowman, self).__init__()\n",
        "        # vocab - vocab built for corpus\n",
        "        # premise_emb - word embedding size for tokens in premise\n",
        "        # hypothesis_emb - word embedding size for tokens in hypothesis\n",
        "        # premise_d - sentence embedding size for premise\n",
        "        # hypothesis_d - sentence embedding size for hypothesis\n",
        "        # lstm_layers - layer number for LSTM model\n",
        "        # dropout - dropout rate for the model\n",
        "        self.embedding = nn.Embedding.from_pretrained(vocab.vectors)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Premise_Enc = nn.LSTM(input_size=premise_emb, hidden_size=premise_d, num_layers=lstm_layers, batch_first=True)\n",
        "        self.Hypothesis_Enc = nn.LSTM(input_size=hypothesis_emb, hidden_size=hypothesis_d, num_layers=lstm_layers, batch_first=True)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.out = nn.Linear(premise_d + hypothesis_d, 3) # batch_size x 3\n",
        "\n",
        "    def forward(self, premise_seq, hypothesis_seq):\n",
        "        premise_seq = self.embedding(premise_seq) # batch_size x seq_len -> batch_size x seq_len x 300\n",
        "        hypothesis_seq = self.embedding(hypothesis_seq) # batch_size x seq_len -> batch_size x seq_len x 300\n",
        "        premise_seq = self.dropout(premise_seq)\n",
        "        hypothesis_seq = self.dropout(hypothesis_seq)\n",
        "\n",
        "        premise_output, _  = self.Premise_Enc(premise_seq) # batch_size x seq_len x 300 -> batch_size x seq_len x 100\n",
        "        hypothesis_output, _  = self.Hypothesis_Enc(hypothesis_seq) # batch_size x seq_len x 300 -> batch_size x seq_len x 100\n",
        "        premise_output = torch.mean(premise_output, 1) # batch_size x seq_len x 100 -> batch_size x 100\n",
        "        hypothesis_output = torch.mean(hypothesis_output, 1) # batch_size x seq_len x 100 -> batch_size x 100\n",
        "        next_in = torch.cat((premise_output, hypothesis_output), 1)  # [batch_size x 100, batch_size x 100] -> batch_size x 200\n",
        "        #next_in = torch.cat((premise_output[ :, -1, :],hypothesis_output[ :, -1, :]), 1)\n",
        "        next_in = self.dropout(next_in)\n",
        "        tanh_out = self.tanh(self.tanh(self.tanh(next_in)))\n",
        "        output = self.out(tanh_out) # batch_size x 200 -> batch_size x 3\n",
        "        return torch.log_softmax(output, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkEf568PJfH",
        "colab_type": "text"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPTYWSOXb6JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bowman_train(model, dataset, criterion, optimizer, epoch_num=5):\n",
        "    # model - model\n",
        "    # dataset - traning set\n",
        "    # criterion - loss function\n",
        "    # optimizer - optimize function\n",
        "    # epoch_num - epoch number\n",
        "    snli = dataset\n",
        "    # file to record average loss for each epoch\n",
        "    record = open(\"result.txt\", \"wb\", buffering=0)\n",
        "    for epoch in range(epoch_num):\n",
        "        # switch to train mode\n",
        "        model.train()\n",
        "\n",
        "        for batch in snli.train_iter:\n",
        "            # get data\n",
        "            premise, _ = batch.premise\n",
        "            hypothesis, _ = batch.hypothesis\n",
        "            label = batch.label\n",
        "\n",
        "            # zeros the parameters gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize step\n",
        "            output = model(premise, hypothesis)\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_acc, train_loss = bowman_eval(model, dataset, \"Train\", criterion)\n",
        "        dev_acc, dev_loss = bowman_eval(model, dataset, \"Dev\", criterion)\n",
        "        # print average loss for the epoch\n",
        "        print('epoch %d train_loss: %.3f dev_loss: %.3f train_acc: %.3f dev_acc: %.3f' % (epoch, train_loss, dev_loss, train_acc, dev_acc))\n",
        "        # save average loss for the epoch\n",
        "        record.write(b'%f\\t%f\\t%f\\t%f\\n' % (train_loss, dev_loss, train_acc, dev_acc))\n",
        "        # save trained model after the epoch\n",
        "        torch.save(model.state_dict(), './model/bowman_%d.pth'% (epoch))\n",
        "\n",
        "    # save final trained model\n",
        "    torch.save(model.state_dict(), './model/bowman_final.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJMEXNWIPi62",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEFApqzysPDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bowman_eval(model, dataset, set_name, criterion):\n",
        "    # model - model\n",
        "    # dataset - evaluation set\n",
        "    snli = dataset\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    batch_iter = None\n",
        "\n",
        "    if set_name == \"Train\":\n",
        "        batch_iter = snli.train_iter\n",
        "    elif set_name == \"Dev\":\n",
        "        batch_iter = snli.dev_iter\n",
        "    elif set_name == \"Test\":\n",
        "        batch_iter = snli.test_iter\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    c_count = 0.\n",
        "    t_count = 0.\n",
        "    epoch_loss = 0.0\n",
        "    for batch in batch_iter:\n",
        "        # get data\n",
        "        premise, _ = batch.premise\n",
        "        hypothesis, _ = batch.hypothesis\n",
        "        label = batch.label\n",
        "\n",
        "        # do predict\n",
        "        output = model(premise, hypothesis)\n",
        "        predict = torch.argmax(output, dim=1)\n",
        "        loss = criterion(output, label)\n",
        "        batch_size = predict.shape\n",
        "\n",
        "        epoch_loss += loss.item() * batch_size[0]\n",
        "\n",
        "        # total number\n",
        "        t_count += batch_size[0]\n",
        "        # correct number\n",
        "        c_count += int(torch.sum(predict == label))\n",
        "    # calcualte the accuracy and print it out\n",
        "    # print(\"%s acc.: %f\" % (set_name, c_count / t_count))\n",
        "    return c_count / t_count, epoch_loss / t_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZQIZGOB2Fx1",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "Initial model, use cross entropy loss and Adam Delta SGD as optimize function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYPnY8SIdxaC",
        "colab_type": "code",
        "outputId": "343e8e60-2d0d-4571-e571-96238b134628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "model = Bowman(snli.TEXT.vocab)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.1)\n",
        "\n",
        "bowman_train(model, snli, criterion, optimizer, epoch_num=5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 train_loss: 0.827 dev_loss: 0.880 train_acc: 0.628 dev_acc: 0.600\n",
            "epoch 1 train_loss: 0.789 dev_loss: 0.854 train_acc: 0.652 dev_acc: 0.615\n",
            "epoch 2 train_loss: 0.767 dev_loss: 0.836 train_acc: 0.663 dev_acc: 0.626\n",
            "epoch 3 train_loss: 0.756 dev_loss: 0.819 train_acc: 0.670 dev_acc: 0.640\n",
            "epoch 4 train_loss: 0.747 dev_loss: 0.811 train_acc: 0.674 dev_acc: 0.644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13D6tPg92c46",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate on Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u99QBJjIsSQ5",
        "colab_type": "code",
        "outputId": "ab143990-1ff8-4404-fc0f-c78d188e4652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        }
      },
      "source": [
        "model = Bowman(snli.TEXT.vocab)\n",
        "model.load_state_dict(torch.load(\"./model/bowman_final.pth\"))\n",
        "model.to(device)\n",
        "acc, loss = bowman_eval(model, snli, \"Train\", criterion)\n",
        "print(\"Train acc.: %.3f, loss : %.3f\" % (acc, loss))\n",
        "acc, loss = bowman_eval(model, snli, \"Test\", criterion)\n",
        "print(\"Test acc.: %.3f, loss : %.3f\" % (acc, loss))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc.: 0.674, loss : 0.746\n",
            "Test acc.: 0.645, loss : 0.814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUbkp3C7QUDT",
        "colab_type": "text"
      },
      "source": [
        "Result for first 5 sentences in test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U38_LPDOQNpX",
        "colab_type": "code",
        "outputId": "bdd8f814-8c59-4028-c4c4-3ea3dfe1209f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "#device = torch.device('cuda')\n",
        "\n",
        "#snli = SNLI(batch_size=32, gpu=device)\n",
        "#model = Bowman(snli.TEXT.vocab)\n",
        "#model.load_state_dict(torch.load(\"./model/bowman_64.pth\"))\n",
        "#model.to(device)\n",
        "\n",
        "# first 5 premises with hypothesis\n",
        "premises = [\"This church choir sings to the masses as they sing joyous songs from the book at a church.\",\n",
        "\"This church choir sings to the masses as they sing joyous songs from the book at a church.\",\n",
        "\"This church choir sings to the masses as they sing joyous songs from the book at a church.\",\n",
        "\"A woman with a green headscarf, blue shirt and a very big grin.\",\n",
        "\"A woman with a green headscarf, blue shirt and a very big grin.\"]\n",
        "\n",
        "hypothesis = [\"The church has cracks in the ceiling.\",\n",
        "\"The church is filled with song.\",\n",
        "\"A choir singing at a baseball game.\",\n",
        "\"The woman is young.\",\n",
        "\"The woman is very happy.\"]\n",
        "\n",
        "# ground truth\n",
        "gold_label = [\"neural\", \"entailment\", \"contradiction\", \"neutral\", \"entailment\"]\n",
        "\n",
        "# tokenize\n",
        "premises_token = [snli.TEXT.preprocess(x) for x in premises]\n",
        "hypothesis_token = [snli.TEXT.preprocess(x) for x in hypothesis]\n",
        "\n",
        "# label list\n",
        "label_vocab = snli.LABEL.vocab.itos\n",
        "preds = []\n",
        "\n",
        "for i in range(len(premises)):\n",
        "    # token to index in vocab\n",
        "    prem, _ = snli.TEXT.numericalize(([premises_token[i]],[len(premises_token[i])]), device=device)\n",
        "    hypo, _ = snli.TEXT.numericalize(([hypothesis_token[i]],[len(hypothesis_token[i])]), device=device)\n",
        "    # do prediction\n",
        "    output = model(prem, hypo)\n",
        "    lab = label_vocab[int(torch.argmax(output))]\n",
        "    preds.append(lab)\n",
        "\n",
        "# print results\n",
        "for i in range(len(premises)):\n",
        "    print(\"Premise: \" + premises[i])\n",
        "    print(\"Hypothesis: \" + hypothesis[i])\n",
        "    print(\"Model Output: \" + preds[i])\n",
        "    print(\"Ground Truth: \" + gold_label[i])\n",
        "    print()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "Hypothesis: The church has cracks in the ceiling.\n",
            "Model Output: contradiction\n",
            "Ground Truth: neural\n",
            "\n",
            "Premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "Hypothesis: The church is filled with song.\n",
            "Model Output: contradiction\n",
            "Ground Truth: entailment\n",
            "\n",
            "Premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "Hypothesis: A choir singing at a baseball game.\n",
            "Model Output: contradiction\n",
            "Ground Truth: contradiction\n",
            "\n",
            "Premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "Hypothesis: The woman is young.\n",
            "Model Output: neutral\n",
            "Ground Truth: neutral\n",
            "\n",
            "Premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "Hypothesis: The woman is very happy.\n",
            "Model Output: neutral\n",
            "Ground Truth: entailment\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV9w65HcGJ3q",
        "colab_type": "text"
      },
      "source": [
        "## Plot train result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDfMOIu6GO63",
        "colab_type": "code",
        "outputId": "8b19ff48-6ffd-4e13-c444-663cd51e15da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "dev_loss = []\n",
        "dev_acc = []\n",
        "\n",
        "with open(\"result.txt\", \"rb\") as f:\n",
        "    for line in f:\n",
        "        line = [float(x) for x in line.strip().split()]\n",
        "        train_loss.append(line[0])\n",
        "        dev_loss.append(line[1])\n",
        "        train_acc.append(line[2])\n",
        "        dev_acc.append(line[3])\n",
        "\n",
        "x = range(len(train_loss))\n",
        "\n",
        "plt.plot(x, train_loss, label='train loss',linewidth=2,color='b') \n",
        "plt.plot(x, dev_loss, label='dev loss',linewidth=2,color='r') \n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc.')\n",
        "plt.title('Bowman\\'s Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncBQ58jqaZe4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY-wxHxiLub2",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y1XYK3YLft-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "5b558a50-a67d-41bc-a6f0-259565f7a2de"
      },
      "source": [
        "def analysis_eval(model, dataset, set_name, neg_set, qua_set, bel_set):\n",
        "\n",
        "    # model - model\n",
        "    # dataset - evaluation set\n",
        "    snli = dataset\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    batch_iter = None\n",
        "\n",
        "    if set_name == \"Dev\":\n",
        "        batch_iter = snli.dev_iter\n",
        "    elif set_name == \"Test\":\n",
        "        batch_iter = snli.test_iter\n",
        "    else:\n",
        "        return\n",
        "    \n",
        "    correct_dict = [0.0] * 9 \n",
        "    total_dict = [0.0] * 9\n",
        "    for batch in batch_iter:\n",
        "        # get data\n",
        "        premise, _ = batch.premise\n",
        "        hypothesis, _ = batch.hypothesis\n",
        "        label = batch.label\n",
        "\n",
        "        # do predict\n",
        "        output = model(premise, hypothesis)\n",
        "        predict = torch.argmax(output, dim=1)\n",
        "\n",
        "        pre_tokens = set(premise[0].cpu().numpy().tolist())\n",
        "        hyp_tokens = set(hypothesis[0].cpu().numpy().tolist())\n",
        "\n",
        "        overlap_num = float(len(set.intersection(pre_tokens, hyp_tokens)))\n",
        "        token_total = float(len(set.union(pre_tokens, hyp_tokens)))\n",
        "\n",
        "        # check for overlap\n",
        "        if (overlap_num/token_total > 0.7):\n",
        "            total_dict[0] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[0] += 1\n",
        "        elif (overlap_num/token_total < 0.3):\n",
        "            total_dict[2] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[2] += 1\n",
        "        else:\n",
        "            total_dict[1] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[1] += 1\n",
        "                \n",
        "        # check for sentence length\n",
        "        if (premise[0].shape[0] > 20 or hypothesis[0].shape[0] > 20):\n",
        "            total_dict[3] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[3] += 1\n",
        "        elif (premise[0].shape[0] < 5 or hypothesis[0].shape[0] < 5):\n",
        "            total_dict[5] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[5] += 1\n",
        "        else:\n",
        "            total_dict[4] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[4] += 1\n",
        "\n",
        "        # check for cotaning specific words\n",
        "        if (len(set.intersection(pre_tokens, neg_set))> 0 or len(set.intersection(hyp_tokens, neg_set))> 0):\n",
        "            total_dict[6] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[6] += 1\n",
        "        if (len(set.intersection(pre_tokens, qua_set))> 0 or len(set.intersection(hyp_tokens, qua_set))> 0):\n",
        "            total_dict[7] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[7] += 1\n",
        "        if (len(set.intersection(pre_tokens, bel_set))> 0 or len(set.intersection(hyp_tokens, bel_set))> 0):\n",
        "            total_dict[8] += 1\n",
        "            if label[0] == predict[0]:\n",
        "                correct_dict[8] += 1\n",
        "\n",
        "    print(\"Overlap:\")\n",
        "    # High: > 70%, Regular: 30%-70%, Low: < 30%\n",
        "    print(\"High: %.3f\\t\\t Regular: %.3f\\t\\t Low: %.3f\" % (correct_dict[0] / total_dict[0], correct_dict[1] / total_dict[1], correct_dict[2] / total_dict[2]))\n",
        "    \n",
        "    print(\"Sentence Length:\")\n",
        "    # Long: > 20, Regular: 5-20, Short: < 5\n",
        "    print(\"Long: %.3f\\t\\t Regular: %.3f\\t\\t Short: %.3f\" % (correct_dict[3] / total_dict[3], correct_dict[4] / total_dict[4], correct_dict[5] / total_dict[5]))\n",
        "    \n",
        "    print(\"Contain Specific Words:\")\n",
        "    print(\"Negation: %.3f\\t\\t Quantifier: %.3f\\t Belief: %.3f\" % (correct_dict[6] / total_dict[6], correct_dict[7] / total_dict[7], correct_dict[8] / total_dict[8]))\n",
        "\n",
        "\n",
        "\n",
        "#device = torch.device('cuda')\n",
        "snli = SNLI(batch_size=1, gpu=device)\n",
        "model = Bowman(snli.TEXT.vocab)\n",
        "model.load_state_dict(torch.load(\"./model/bowman_48.pth\"))\n",
        "model.to(device)\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# build list for type of specific words\n",
        "neg = [\"no\", \"not\", \"none\", \"nobody\", \"nothing\", \"neither\", \"nowhere\", \"never\", \"hardly\", \"barely\", \"doesnt\", \"isnt\", \"wasnt\", \"shouldnt\", \"wouldnt\", \"couldnt\", \"wont\", \"cant\", \"dont\"]\n",
        "qua = [\"much\", \"enough\", \"more\", \"most\", \"less\", \"least\", \"no\", \"none\", \"some\", \"any\", \"many\", \"few\", \"several\", \"almost\", \"nearly\"]\n",
        "bel = [\"know\", \"believe\", \"understand\", \"doubt\", \"think\", \"suppose\", \"recognize\", \"forget\", \"remember\", \"imagine\", \"mean\", \"agree\", \"disagree\", \"deny\", \"promise\"]\n",
        "\n",
        "neg_set, qua_set, bel_set = [], [], []\n",
        "\n",
        "for token in neg:\n",
        "    if token in snli.TEXT.vocab.stoi:\n",
        "        neg_set.append(snli.TEXT.vocab.stoi[token])\n",
        "for token in qua:\n",
        "    if token in snli.TEXT.vocab.stoi:\n",
        "        qua_set.append(snli.TEXT.vocab.stoi[token])\n",
        "for token in bel:\n",
        "    if token in snli.TEXT.vocab.stoi:\n",
        "        bel_set.append(snli.TEXT.vocab.stoi[token])\n",
        "\n",
        "neg_set, qua_set, bel_set = set(neg_set), set(qua_set), set(bel_set)\n",
        "analysis_eval(model, snli, \"Test\", neg_set, qua_set, bel_set)\n",
        "#acc, loss = bowman_eval(model, snli, \"Train\", criterion)\n",
        "#acc, loss = bowman_eval(model, snli, \"Test\", criterion)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overlap:\n",
            "High: 0.574\t\t Regular: 0.628\t\t Low: 0.661\n",
            "Sentence Length:\n",
            "Long: 0.656\t\t Regular: 0.648\t\t Short: 0.643\n",
            "Contain Specific Words:\n",
            "Negation: 0.735\t\t Quantifier: 0.668\t Belief: 0.857\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}