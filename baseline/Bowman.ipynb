{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bowman.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhBAy7RsMdDc",
        "colab_type": "text"
      },
      "source": [
        "# Bowman's Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut10idNFMQ71",
        "colab_type": "text"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dKfdbsQDgJh",
        "colab_type": "code",
        "outputId": "0bd6bb52-a603-4b67-dc40-e6596ba2326b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext.data import Dataset\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "from nltk import word_tokenize\n",
        "import time\n",
        "import dill\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUcE6lFVMsnW",
        "colab_type": "text"
      },
      "source": [
        "## Make directories\n",
        "Make directories for saving data and model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU4j19JiV2kZ",
        "colab_type": "code",
        "outputId": "10dc7995-d6e6-4484-cc0a-1659270ed796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "\n",
        "# claim directories for saving data and model\n",
        "new_dir = ['./data', './model', './data/snli_split']\n",
        "\n",
        "# if directories not exist, make new directory\n",
        "for dir in new_dir:\n",
        "    if not os.path.exists(dir):\n",
        "        print('mkdir:', dir)\n",
        "        os.mkdir(dir)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: ./data\n",
            "mkdir: ./model\n",
            "mkdir: ./data/snli_split\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY_HL4ngM839",
        "colab_type": "text"
      },
      "source": [
        "## SNLI corpus data preprocessing\n",
        "The class to preprocess SNLI corpus.\n",
        "\n",
        "For the first time on initial, the initial function will download and split SNLI corpus to train, dev and test sets, build vocab for the corpus by using Glove 840B 300d and store them to local files. And it will also generate batch iterator for the sets. This process may take more than 5 minutes on first time.\n",
        "\n",
        "After the first time, initial function will check existence of local files, if exists, it will load directly from local file and thus can save a lot of time (within 1 minute)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T62lOGEWGhZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SNLIDataset(Dataset):\n",
        "    @staticmethod\n",
        "    def sort_key(ex):\n",
        "        return data.interleave_keys(len(ex.premise), len(ex.hypothesis))\n",
        "\n",
        "# preprocess SNLI corpus to save time and give train, dev, test sets\n",
        "class SNLI(object):\n",
        "    def __init__(self, batch_size=4, gpu=torch.device('cuda')):\n",
        "        # set file name for train dev test sets\n",
        "        self.snli_split_path_lst = ['./data/snli_split/train', './data/snli_split/dev', './data/snli_split/test']\n",
        "\n",
        "        # set data field for text and label\n",
        "        self.TEXT = data.Field(batch_first=True, include_lengths=True, tokenize=word_tokenize, lower=True)\n",
        "        self.LABEL = data.Field(sequential=False, unk_token=None)\n",
        "\n",
        "        # split corpus\n",
        "        if self.if_splited():\n",
        "            # if already splited, load local sets\n",
        "            fields = {'premise': self.TEXT, 'hypothesis': self.TEXT, 'label': self.LABEL}\n",
        "            self.train, self.dev, self.test = self.load_split_datasets(fields)\n",
        "        else:\n",
        "            # split corpus to train, dev, test sets and save them to local\n",
        "            self.train, self.dev, self.test = datasets.SNLI.splits(self.TEXT, self.LABEL, root='data')\n",
        "            self.save_splited_sets(self.train, self.dev, self.test)\n",
        "\n",
        "\n",
        "        # build vocab for corpus\n",
        "        if os.path.exists('./data/snli_split/text_vocab') and os.path.exists('./data/snli_split/label_vocab'):\n",
        "            # if local vocab exists, load local vocab into model\n",
        "            with open('./data/snli_split/text_vocab', 'rb')as f:\n",
        "                self.TEXT.vocab = dill.load(f)\n",
        "            with open('./data/snli_split/label_vocab', 'rb')as f:\n",
        "                self.LABEL.vocab = dill.load(f)\n",
        "        else:\n",
        "            # build vocab for corpus and save it to local\n",
        "            self.TEXT.build_vocab(self.train, self.dev, self.test, vectors=GloVe(name='840B', dim=300))\n",
        "            self.LABEL.build_vocab(self.train)\n",
        "            with open('./data/snli_split/text_vocab', 'wb')as f:\n",
        "                dill.dump(self.TEXT.vocab, f)\n",
        "            with open('./data/snli_split/label_vocab', 'wb')as f:\n",
        "                dill.dump(self.LABEL.vocab, f)\n",
        "\n",
        "\n",
        "        # generate batch iterator\n",
        "        self.train_iter, self.dev_iter, self.test_iter =  data.BucketIterator.splits((self.train, self.dev, self.test), batch_size=batch_size, device=gpu)\n",
        "\n",
        "    # check local train, dev, test sets\n",
        "    def if_splited(self):\n",
        "        for path in self.snli_split_path_lst:\n",
        "            if not os.path.exists(path):\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "    # load dataset from local\n",
        "    def load_split_datasets(self, fields):\n",
        "        # load from local\n",
        "        with open('./data/snli_split/train', 'rb')as f:\n",
        "            train_examples = dill.load(f)\n",
        "        with open('./data/snli_split/dev', 'rb')as f:\n",
        "            dev_examples = dill.load(f)\n",
        "        with open('./data/snli_split/test', 'rb')as f:\n",
        "            test_examples = dill.load(f)\n",
        "\n",
        "        # recover\n",
        "        train = SNLIDataset(examples=train_examples, fields=fields)\n",
        "        dev = SNLIDataset(examples=dev_examples, fields=fields)\n",
        "        test = SNLIDataset(examples=test_examples, fields=fields)\n",
        "        return train, dev, test\n",
        "\n",
        "    # save datasets to local\n",
        "    def save_splited_sets(self, train, dev, test):\n",
        "        # save to local\n",
        "        with open('./data/snli_split/train', 'wb')as f:\n",
        "            dill.dump(train.examples, f)\n",
        "        with open('./data/snli_split/dev', 'wb')as f:\n",
        "            dill.dump(dev.examples, f)\n",
        "        with open('./data/snli_split/test', 'wb')as f:\n",
        "            dill.dump(test.examples, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGkJYKinOdrH",
        "colab_type": "text"
      },
      "source": [
        "## Initialize SNLI class and do preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4zrNONWwSi",
        "colab_type": "code",
        "outputId": "6a2d763b-94c3-4538-c276-89bbf18acfe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "device = torch.device('cuda')\n",
        "snli = SNLI(batch_size=32, gpu=device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading snli_1.0.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "snli_1.0.zip: 100%|██████████| 94.6M/94.6M [00:07<00:00, 12.3MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [17:00, 2.13MB/s]                           \n",
            "100%|█████████▉| 2195732/2196017 [04:56<00:00, 7907.78it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "166rJ755O7jY",
        "colab_type": "text"
      },
      "source": [
        "## Bowman's Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UHTtZ3-b1QD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bowman(nn.Module):\n",
        "    def __init__(self, vocab, premise_emb=300, hypothesis_emb=300, premise_d=100, hypothesis_d=100, lstm_layers=1, dropout=0.1):\n",
        "        super(Bowman, self).__init__()\n",
        "        # vocab - vocab built for corpus\n",
        "        # premise_emb - word embedding size for tokens in premise\n",
        "        # hypothesis_emb - word embedding size for tokens in hypothesis\n",
        "        # premise_d - sentence embedding size for premise\n",
        "        # hypothesis_d - sentence embedding size for hypothesis\n",
        "        # lstm_layers - layer number for LSTM model\n",
        "        # dropout - dropout rate for the model\n",
        "        self.embedding = nn.Embedding.from_pretrained(vocab.vectors)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.Premise_Enc = nn.LSTM(input_size=premise_emb, hidden_size=premise_d, num_layers=lstm_layers, batch_first=True)\n",
        "        self.Hypothesis_Enc = nn.LSTM(input_size=hypothesis_emb, hidden_size=hypothesis_d, num_layers=lstm_layers, batch_first=True)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.out = nn.Linear(premise_d + hypothesis_d, 3) # batch_size x 3\n",
        "\n",
        "    def forward(self, premise_seq, hypothesis_seq):\n",
        "        premise_seq = self.embedding(premise_seq) # batch_size x seq_len -> batch_size x seq_len x 300\n",
        "        hypothesis_seq = self.embedding(hypothesis_seq) # batch_size x seq_len -> batch_size x seq_len x 300\n",
        "        premise_seq = self.dropout(premise_seq)\n",
        "        hypothesis_seq = self.dropout(hypothesis_seq)\n",
        "\n",
        "        premise_output, _  = self.Premise_Enc(premise_seq) # batch_size x seq_len x 300 -> batch_size x seq_len x 100\n",
        "        hypothesis_output, _  = self.Hypothesis_Enc(hypothesis_seq) # batch_size x seq_len x 300 -> batch_size x seq_len x 100\n",
        "        premise_output = torch.mean(premise_output, 1) # batch_size x seq_len x 100 -> batch_size x 100\n",
        "        hypothesis_output = torch.mean(hypothesis_output, 1) # batch_size x seq_len x 100 -> batch_size x 100\n",
        "        next_in = torch.cat((premise_output, hypothesis_output), 1)  # [batch_size x 100, batch_size x 100] -> batch_size x 200\n",
        "        #next_in = torch.cat((premise_output[ :, -1, :],hypothesis_output[ :, -1, :]), 1)\n",
        "        next_in = self.dropout(next_in)\n",
        "        tanh_out = self.tanh(self.tanh(self.tanh(next_in)))\n",
        "        output = self.out(tanh_out) # batch_size x 200 -> batch_size x 3\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkEf568PJfH",
        "colab_type": "text"
      },
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPTYWSOXb6JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bowman_train(model, dataset, criterion, optimizer, epoch_num=5):\n",
        "    # model - model\n",
        "    # dataset - traning set\n",
        "    # criterion - loss function\n",
        "    # optimizer - optimize function\n",
        "    # epoch_num - epoch number\n",
        "    snli = dataset\n",
        "    # file to record average loss for each epoch\n",
        "    record = open(\"result.txt\", \"wb\", buffering=0)\n",
        "    for epoch in range(epoch_num):\n",
        "        # switch to train mode\n",
        "        model.train()\n",
        "\n",
        "        for batch in snli.train_iter:\n",
        "            # get data\n",
        "            premise, _ = batch.premise\n",
        "            hypothesis, _ = batch.hypothesis\n",
        "            label = batch.label\n",
        "\n",
        "            # zeros the parameters gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize step\n",
        "            output = model(premise, hypothesis)\n",
        "            loss = criterion(output, label)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_acc, train_loss = bowman_eval(model, dataset, \"Train\", criterion)\n",
        "        dev_acc, dev_loss = bowman_eval(model, dataset, \"Dev\", criterion)\n",
        "        # print average loss for the epoch\n",
        "        print('epoch %d train_loss: %.3f dev_loss: %.3f train_acc: %.3f dev_acc: %.3f' % (epoch, train_loss, dev_loss, train_acc, dev_acc))\n",
        "        # save average loss for the epoch\n",
        "        record.write(b'%f\\t%f\\t%f\\t%f\\n' % (train_loss, dev_loss, train_acc, dev_acc))\n",
        "        # save trained model after the epoch\n",
        "        torch.save(model.state_dict(), './model/bowman_%d.pth'% (epoch))\n",
        "\n",
        "    # save final trained model\n",
        "    torch.save(model.state_dict(), './model/bowman_final.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJMEXNWIPi62",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEFApqzysPDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bowman_eval(model, dataset, set_name, criterion):\n",
        "    # model - model\n",
        "    # dataset - evaluation set\n",
        "    snli = dataset\n",
        "\n",
        "    # switch to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    batch_iter = None\n",
        "\n",
        "    if set_name == \"Train\":\n",
        "        batch_iter = snli.train_iter\n",
        "    elif set_name == \"Dev\":\n",
        "        batch_iter = snli.dev_iter\n",
        "    elif set_name == \"Test\":\n",
        "        batch_iter = snli.test_iter\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    c_count = 0.\n",
        "    t_count = 0.\n",
        "    epoch_loss = 0.0\n",
        "    for batch in batch_iter:\n",
        "        # get data\n",
        "        premise, _ = batch.premise\n",
        "        hypothesis, _ = batch.hypothesis\n",
        "        label = batch.label\n",
        "\n",
        "        # do predict\n",
        "        output = model(premise, hypothesis)\n",
        "        predict = torch.argmax(output, dim=1)\n",
        "        loss = criterion(output, label)\n",
        "        batch_size = predict.shape\n",
        "\n",
        "        epoch_loss += loss.item() * batch_size[0]\n",
        "\n",
        "        # total number\n",
        "        t_count += batch_size[0]\n",
        "        # correct number\n",
        "        c_count += int(torch.sum(predict == label))\n",
        "    # calcualte the accuracy and print it out\n",
        "    # print(\"%s acc.: %f\" % (set_name, c_count / t_count))\n",
        "    return c_count / t_count, epoch_loss / t_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZQIZGOB2Fx1",
        "colab_type": "text"
      },
      "source": [
        "## Train the model\n",
        "Initial model, use cross entropy loss and Adam Delta SGD as optimize function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYPnY8SIdxaC",
        "colab_type": "code",
        "outputId": "9adbcda5-3139-4254-e760-38e3db546692",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "model = Bowman(snli.TEXT.vocab)\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adadelta(model.parameters(), lr=0.01)\n",
        "\n",
        "bowman_train(model, snli, criterion, optimizer, epoch_num=5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 train_loss: 1.008 dev_loss: 1.031 train_acc: 0.505 dev_acc: 0.480\n",
            "epoch 1 train_loss: 0.919 dev_loss: 0.946 train_acc: 0.572 dev_acc: 0.571\n",
            "epoch 2 train_loss: 0.888 dev_loss: 0.928 train_acc: 0.595 dev_acc: 0.582\n",
            "epoch 3 train_loss: 0.867 dev_loss: 0.918 train_acc: 0.608 dev_acc: 0.588\n",
            "epoch 4 train_loss: 0.851 dev_loss: 0.906 train_acc: 0.617 dev_acc: 0.594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13D6tPg92c46",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate on Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u99QBJjIsSQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "77147138-110e-45aa-a8aa-c8dccc6358c5"
      },
      "source": [
        "model = Bowman(snli.TEXT.vocab)\n",
        "model.load_state_dict(torch.load(\"./model/bowman_final.pth\"))\n",
        "model.to(device)\n",
        "acc, loss = bowman_eval(model, snli, \"Train\", criterion)\n",
        "print(\"Train acc.: %.3f, loss : %.3f\" % (acc, loss))\n",
        "acc, loss = bowman_eval(model, snli, \"Test\", criterion)\n",
        "print(\"Test acc.: %.3f, loss : %.3f\" % (acc, loss))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc.: 0.617, loss : 0.851\n",
            "Test acc.: 0.585, loss : 0.909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUbkp3C7QUDT",
        "colab_type": "text"
      },
      "source": [
        "Result for first 5 sentences in test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U38_LPDOQNpX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "5fe69e03-a4f3-4e41-b917-b151c20a1192"
      },
      "source": [
        "#device = torch.device('cuda')\n",
        "\n",
        "#snli = SNLI(batch_size=32, gpu=device)\n",
        "#model = Bowman(snli.TEXT.vocab)\n",
        "#model.load_state_dict(torch.load(\"./model/bowman_64.pth\"))\n",
        "#model.to(device)\n",
        "\n",
        "# first 5 premises with hypothesis\n",
        "premises = [\"This church choir sings to the masses as they sing joyous songs from the book at a church.\",\n",
        "\"This church choir sings to the masses as they sing joyous songs from the book at a church.\",\n",
        "\"This church choir sings to the masses as they sing joyous songs from the book at a church.\",\n",
        "\"A woman with a green headscarf, blue shirt and a very big grin.\",\n",
        "\"A woman with a green headscarf, blue shirt and a very big grin.\"]\n",
        "\n",
        "hypothesis = [\"The church has cracks in the ceiling.\",\n",
        "\"The church is filled with song.\",\n",
        "\"A choir singing at a baseball game.\",\n",
        "\"The woman is young.\",\n",
        "\"The woman is very happy.\"]\n",
        "\n",
        "# ground truth\n",
        "gold_label = [\"neural\", \"entailment\", \"contradiction\", \"neural\", \"entailment\"]\n",
        "\n",
        "# tokenize\n",
        "premises_token = [snli.TEXT.preprocess(x) for x in premises]\n",
        "hypothesis_token = [snli.TEXT.preprocess(x) for x in hypothesis]\n",
        "\n",
        "# label list\n",
        "label_vocab = snli.LABEL.vocab.itos\n",
        "preds = []\n",
        "\n",
        "for i in range(len(premises)):\n",
        "    # token to index in vocab\n",
        "    prem, _ = snli.TEXT.numericalize(([premises_token[i]],[len(premises_token[i])]), device=device)\n",
        "    hypo, _ = snli.TEXT.numericalize(([hypothesis_token[i]],[len(hypothesis_token[i])]), device=device)\n",
        "    # do prediction\n",
        "    output = model(prem, hypo)\n",
        "    lab = label_vocab[int(torch.argmax(output))]\n",
        "    preds.append(lab)\n",
        "\n",
        "# print results\n",
        "for i in range(len(premises)):\n",
        "    print(\"Premise: \" + premises[i])\n",
        "    print(\"Hypothesis: \" + hypothesis[i])\n",
        "    print(\"Model Output: \" + preds[i])\n",
        "    print(\"Ground Truth: \" + gold_label[i])\n",
        "    print()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "Hypothesis: The church has cracks in the ceiling.\n",
            "Model Output: contradiction\n",
            "Ground Truth: neural\n",
            "\n",
            "Premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "Hypothesis: The church is filled with song.\n",
            "Model Output: contradiction\n",
            "Ground Truth: entailment\n",
            "\n",
            "Premise: This church choir sings to the masses as they sing joyous songs from the book at a church.\n",
            "Hypothesis: A choir singing at a baseball game.\n",
            "Model Output: contradiction\n",
            "Ground Truth: contradiction\n",
            "\n",
            "Premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "Hypothesis: The woman is young.\n",
            "Model Output: neutral\n",
            "Ground Truth: neural\n",
            "\n",
            "Premise: A woman with a green headscarf, blue shirt and a very big grin.\n",
            "Hypothesis: The woman is very happy.\n",
            "Model Output: neutral\n",
            "Ground Truth: entailment\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV9w65HcGJ3q",
        "colab_type": "text"
      },
      "source": [
        "## Plot train result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDfMOIu6GO63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "5c79b2b7-ce60-4838-b4f8-068d98fa0715"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = []\n",
        "train_acc = []\n",
        "dev_loss = []\n",
        "dev_acc = []\n",
        "\n",
        "with open(\"result.txt\", \"rb\") as f:\n",
        "    for line in f:\n",
        "        line = [float(x) for x in line.strip().split()]\n",
        "        train_loss.append(line[0])\n",
        "        dev_loss.append(line[1])\n",
        "        train_acc.append(line[2])\n",
        "        dev_acc.append(line[3])\n",
        "\n",
        "x = range(len(train_loss))\n",
        "\n",
        "plt.plot(x, train_loss, label='train loss',linewidth=2,color='b') \n",
        "plt.plot(x, dev_loss, label='dev loss',linewidth=2,color='r') \n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('acc.')\n",
        "plt.title('Bowman\\'s Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nov8PGajmaNR6erQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}